# -*- coding: utf-8 -*-


# ==============================================================================
# å¯é€‰å‚è€ƒå—: å®‰è£… Conda + æ„å»º Python 3.9 ç¯å¢ƒ + å…‹éš†å®˜æ–¹ jax3dï¼ˆä¸€èˆ¬å¯ä»¥è·³è¿‡ï¼‰
# è¯´æ˜: ä»…å½“ä½ éœ€è¦å¯¹ç…§å®˜æ–¹åŸç‰ˆä»“åº“æ—¶å†è¿è¡Œè¿™ä¸€å—ï¼›
#      å¸¸è§„è®­ç»ƒå»ºè®®ç›´æ¥ä»ä¸‹æ–¹ Cell 1 å¼€å§‹ï¼Œä½¿ç”¨ jax3d_David ä»“åº“ã€‚
# ==============================================================================
import os

print("â³ æ­£åœ¨å®‰è£… Conda (å¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿ)...")
!pip install -q condacolab
import condacolab
condacolab.install()

import time
time.sleep(5) # ç»™å®ƒä¸€ç‚¹æ—¶é—´ååº”
print("âœ… Conda å®‰è£…å®Œæˆï¼æ­£åœ¨é…ç½® Python 3.9 ç¯å¢ƒ...")

# åˆ›å»ºç¯å¢ƒå¹¶é”æ­» JAX ç‰ˆæœ¬ (0.3.25)
!conda create -n mobilenerf python=3.9 -y
!source activate mobilenerf && conda install -c conda-forge cudatoolkit=11.8 cudnn=8.8 -y
# ä½¿ç”¨ --no-deps é˜²æ­¢ pip è‡ªåŠ¨å‡çº§ JAX
!source activate mobilenerf && pip install "jax[cuda11_pip]==0.3.25" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html --no-deps
# æ‰‹åŠ¨è¡¥é½ JAX ä¾èµ–
!source activate mobilenerf && pip install "flax==0.5.3" scipy "optax==0.1.4" "chex==0.1.5" "absl-py" --no-deps
# å®‰è£…å…¶ä»–å·¥å…·
!source activate mobilenerf && pip install tqdm opencv-python-headless matplotlib gin-config msgpack typing-extensions opt_einsum toolz rich PyYAML numpy==1.23.5
!source activate mobilenerf && conda install -c pytorch -c nvidia pytorch torchvision torchaudio pytorch-cuda=11.8 -y
!source activate mobilenerf && conda install -c pytorch3d pytorch3d -y

# ä¸‹è½½ä»£ç 
if not os.path.exists('/content/jax3d'):
    !git clone https://github.com/google-research/jax3d.git

print("âœ… ç¯å¢ƒæ­å»ºå®Œæ¯•ï¼JAX ç‰ˆæœ¬å·²é”æ­»ä¸º 0.3.25")

"""# Cell 1: ä¸€é”®é…ç½®ç¯å¢ƒ + æ‹‰å– jax3d_David ä»“åº“ï¼ˆæ¨èé»˜è®¤ï¼‰"""

# ==============================================================================
# Cell 1: ä¸€é”®é…ç½®ç¯å¢ƒ + æ‹‰å– Dave çš„ä¿®å¤ç‰ˆä»£ç 
# ==============================================================================
import os
import time
import shutil

# --- 1. å®‰è£…åŸºç¡€ç¯å¢ƒ (Conda) ---
print("â³ æ­£åœ¨å®‰è£… Conda...")
try:
    import condacolab
except ImportError:
    !pip install -q condacolab
    import condacolab
condacolab.install()
time.sleep(5)

print("âœ… Conda å°±ç»ªï¼é…ç½® Python 3.9 + JAX...")

# --- 2. é…ç½® Python ç¯å¢ƒ (é”æ­»ç‰ˆæœ¬) ---
!conda create -n mobilenerf python=3.9 -y
# å®‰è£… CUDA, JAX, Flax (å¿…é¡»ä¸¥æ ¼åŒ¹é…)
!source activate mobilenerf && conda install -c conda-forge cudatoolkit=11.8 cudnn=8.8 -y
!source activate mobilenerf && pip install "jax[cuda11_pip]==0.3.25" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html --no-deps
!source activate mobilenerf && pip install "flax==0.5.3" scipy "optax==0.1.4" "chex==0.1.5" "absl-py" --no-deps
!source activate mobilenerf && pip install tqdm opencv-python-headless matplotlib gin-config msgpack typing-extensions opt_einsum toolz rich PyYAML numpy==1.23.5
!source activate mobilenerf && conda install -c pytorch -c nvidia pytorch torchvision torchaudio pytorch-cuda=11.8 -y
!source activate mobilenerf && conda install -c pytorch3d pytorch3d -y

print("âœ… è¿è¡Œç¯å¢ƒæ­å»ºå®Œæ¯•ï¼")

# --- 3. æ‹‰å–ä½ çš„ GitHub ä»£ç  (jax3d_David) ---
# ä½ çš„ä»“åº“åœ°å€
MY_REPO = "https://github.com/Davecodingking/jax3d_David.git"
TARGET_DIR = "/content/jax3d"

print(f"ğŸš€ æ­£åœ¨æ‹‰å–ä½ çš„ä»£ç : {MY_REPO}")

# æ¸…ç†æ—§ç›®å½•
if os.path.exists(TARGET_DIR): shutil.rmtree(TARGET_DIR)
if os.path.exists("/content/jax3d_David"): shutil.rmtree("/content/jax3d_David")

# å…‹éš†ä»“åº“
!git clone {MY_REPO}

# ç»“æ„ä¿®æ­£: æŠŠ jax3d_David æ”¹åä¸º jax3d (Python æ‰èƒ½è¯†åˆ«)
if os.path.exists("/content/jax3d_David"):
    shutil.move("/content/jax3d_David", TARGET_DIR)
    print("âœ… ä»£ç å·²å°±ä½ (jax3d_David -> jax3d)")
else:
    print("âŒ å…‹éš†å¤±è´¥ï¼Œè¯·æ£€æŸ¥ GitHub ä»“åº“æ˜¯å¦ä¸ºç©ºæˆ–åœ°å€é”™è¯¯ã€‚")

print("ğŸ‰ å‡†å¤‡å°±ç»ªï¼è¯·ä¸Šä¼ æ•°æ®åŒ… MyNeRFData.zip å¹¶è¿è¡Œä¸‹ä¸€æ­¥ã€‚")

"""# Cell 2: æ‰“åŒ…å½“å‰ jax3d ä»“åº“ï¼ˆå¯é€‰ï¼‰"""

import shutil
import os
from google.colab import files

# 1. å®šä¹‰æ‰“åŒ…ç›®æ ‡ï¼šæ•´ä¸ª jax3d ä»“åº“ (åŒ…å«ä¿®å¥½çš„ mobilenerf)
source_dir = '/content/jax3d'
output_filename = '/content/jax3d_fixed_final'

print(f"ğŸ“¦ æ­£åœ¨æ‰“åŒ…ä¿®å¤åçš„ä»£ç åº“: {source_dir} ...")
print("   (è¿™åŒ…å«äº† Scale=0.033, No-Gamma, RGB-Fix çš„æ‰€æœ‰ä¿®æ”¹)")

# 2. å‹ç¼©
shutil.make_archive(output_filename, 'zip', source_dir)

print(f"âœ… æ‰“åŒ…å®Œæˆ: {output_filename}.zip")
print("â¬‡ï¸ è¯·åœ¨å·¦ä¾§æ–‡ä»¶æ æ‰¾åˆ° 'jax3d_fixed_final.zip'ï¼Œå³é”®ä¸‹è½½å¹¶å¦¥å–„ä¿å­˜ï¼")
# files.download(output_filename + '.zip') # ä½ å¯ä»¥æ‰‹åŠ¨å–æ¶ˆæ³¨é‡Šè®©å®ƒè‡ªåŠ¨ä¸‹è½½

# --- 3. æ‹‰å–ä½ çš„ GitHub ä»£ç  (jax3d_David) ---
# ä½ çš„ä»“åº“åœ°å€
MY_REPO = "https://github.com/Davecodingking/jax3d_David.git"
TARGET_DIR = "/content/jax3d"

print(f"ğŸš€ æ­£åœ¨æ‹‰å–ä½ çš„ä»£ç : {MY_REPO}")

# æ¸…ç†æ—§ç›®å½•
if os.path.exists(TARGET_DIR): shutil.rmtree(TARGET_DIR)
if os.path.exists("/content/jax3d_David"): shutil.rmtree("/content/jax3d_David")

# å…‹éš†ä»“åº“
!git clone {MY_REPO}

# ç»“æ„ä¿®æ­£: æŠŠ jax3d_David æ”¹åä¸º jax3d (Python æ‰èƒ½è¯†åˆ«)
if os.path.exists("/content/jax3d_David"):
    shutil.move("/content/jax3d_David", TARGET_DIR)
    print("âœ… ä»£ç å·²å°±ä½ (jax3d_David -> jax3d)")
else:
    print("âŒ å…‹éš†å¤±è´¥ï¼Œè¯·æ£€æŸ¥ GitHub ä»“åº“æ˜¯å¦ä¸ºç©ºæˆ–åœ°å€é”™è¯¯ã€‚")

print("ğŸ‰ å‡†å¤‡å°±ç»ªï¼è¯·ä¸Šä¼ æ•°æ®åŒ… MyNeRFData.zip å¹¶è¿è¡Œä¸‹ä¸€æ­¥ã€‚")

"""# Cell 3: æ•°æ®å‡†å¤‡ï¼ˆè§£å‹ Dataset + ç»“æ„ä¿®å¤ + æŒ‚è½½ Driveï¼‰"""

# ==========================================
# æ­¥éª¤ 2 (ä¿®å¤ç‰ˆ): æ™ºèƒ½è§£å‹ä¸å®Œæ•´æ€§æ£€æŸ¥
# è¯´æ˜ï¼šè¯·ä¿è¯ ZIP å†…éƒ¨é¡¶å±‚æ–‡ä»¶å¤¹å‘½åä¸º MyNeRFDataï¼Œ
#       ä¸”æœ€ç»ˆå±•å¼€è·¯å¾„ä¸º data/custom/MyNeRFDataï¼Œå¯¹åº” mobilenerf ä¸­ object_name="MyNeRFData"
# ==========================================
import os
import zipfile

zip_path = '/content/MyNeRFData.zip'
extract_path = '/content/jax3d/jax3d/projects/mobilenerf/data/custom/MyNeRFData'

# 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if not os.path.exists(zip_path):
    print("âŒ é”™è¯¯ï¼šæ ¹æœ¬æ²¡æ‰¾åˆ° /content/MyNeRFData.zipï¼")
    print("ğŸ‘‰ è¯·å°†æ–‡ä»¶æ‹–å…¥å·¦ä¾§æ–‡ä»¶æ ï¼Œå¹¶ç­‰å¾…ä¸Šä¼ å®Œæˆã€‚")
    assert False

# 2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æŸå (å…³é”®æ­¥éª¤)
if not zipfile.is_zipfile(zip_path):
    print("âŒ è‡´å‘½é”™è¯¯ï¼šZIP æ–‡ä»¶å·²æŸåæˆ–æœªä¸Šä¼ å®Œæˆï¼")
    print("ğŸ’¡ åŸå› ï¼šé€šå¸¸æ˜¯å› ä¸ºä½ åœ¨ä¸Šä¼ è¿›åº¦æ¡èµ°å®Œä¹‹å‰å°±ç‚¹å‡»äº†è¿è¡Œã€‚")
    print("ğŸ‘‰ è§£å†³ï¼šè¯·åœ¨å·¦ä¾§åˆ é™¤è¯¥æ–‡ä»¶ï¼Œé‡æ–°ä¸Šä¼ ï¼ŒåŠ¡å¿…ç­‰å¾…ä¸‹æ–¹è¿›åº¦åœˆå®Œå…¨æ¶ˆå¤±ï¼")
    # æ‰“å°æ–‡ä»¶å¤§å°çœ‹çœ‹
    file_size = os.path.getsize(zip_path) / (1024 * 1024)
    print(f"   å½“å‰æ–‡ä»¶å¤§å°ä»…ä¸º: {file_size:.2f} MB (å¦‚æœè¿™ä¸ªæ•°å¾ˆå°ï¼Œè¯´æ˜è‚¯å®šæ²¡ä¼ å®Œ)")
    assert False

print(f"âœ… ZIP æ–‡ä»¶å®Œæ•´ ({os.path.getsize(zip_path)/1024/1024:.2f} MB)ã€‚å‡†å¤‡è§£å‹...")

# 3. åˆ›å»ºç›®å½•
if not os.path.exists(extract_path):
    os.makedirs(extract_path)

# 4. è§£å‹
print(f"ğŸ“‚ æ­£åœ¨è§£å‹åˆ°: {extract_path}")
# ä½¿ç”¨ python è‡ªå¸¦åº“è§£å‹ï¼Œæ¯” shell å‘½ä»¤æ›´ç¨³
try:
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    print("âœ… è§£å‹æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ è§£å‹å¤±è´¥: {e}")
    assert False

# 5. å†æ¬¡æ ¸å®å†…å®¹
# æœ‰æ—¶å€™ zip åŒ…é‡Œè‡ªå¸¦äº†ä¸€å±‚æ–‡ä»¶å¤¹ï¼Œæˆ‘ä»¬éœ€è¦ç¡®è®¤ json åœ¨å“ª
print("ğŸ§ æ ¸å®æ–‡ä»¶ä½ç½®...")
found_json = False
for root, dirs, files in os.walk(extract_path):
    if "transforms_train.json" in files:
        print(f"âœ… æˆåŠŸæ‰¾åˆ°é…ç½®æ–‡ä»¶: {os.path.join(root, 'transforms_train.json')}")
        found_json = True
        break

if not found_json:
    print("âš ï¸ è­¦å‘Šï¼šè§£å‹æˆåŠŸï¼Œä½†æ²¡æ‰¾åˆ° transforms_train.jsonã€‚")
    print("ğŸ‘‡ è¯·æ£€æŸ¥ä¸‹é¢çš„æ–‡ä»¶ç»“æ„ï¼Œçœ‹çœ‹æ˜¯ä¸æ˜¯å¥—äº†ä¸€å±‚æ–‡ä»¶å¤¹ï¼Ÿ")
    for root, dirs, files in os.walk(extract_path):
        level = root.replace(extract_path, '').count(os.sep)
        indent = ' ' * 4 * (level)
        print('{}{}/'.format(indent, os.path.basename(root)))
        subindent = ' ' * 4 * (level + 1)
        for f in files[:5]: # åªæ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶
            print('{}{}'.format(subindent, f))
else:
    print("ğŸ‰ æ•°æ®å‡†å¤‡å®Œç¾å°±ç»ªï¼è¯·ç»§ç»­è¿è¡Œ Step 3ã€‚")

import os
import shutil

nested_dir = '/content/jax3d/jax3d/projects/mobilenerf/data/custom/MyNeRFData/MyNeRFData'
target_dir = '/content/jax3d/jax3d/projects/mobilenerf/data/custom/MyNeRFData'

print("ğŸ”§ æ­£åœ¨æ£€æµ‹æ˜¯å¦å¥—å¨ƒ...")

if os.path.exists(nested_dir):
    print(f"âš ï¸ å‘ç°å¥—å¨ƒæ–‡ä»¶å¤¹ï¼æ­£åœ¨æŠŠæ–‡ä»¶ä» {nested_dir} æ¬å‡ºæ¥...")

    # éå†å¥—å¨ƒæ–‡ä»¶å¤¹é‡Œçš„æ‰€æœ‰æ–‡ä»¶ï¼Œç§»åŠ¨åˆ°å¤–é¢
    for filename in os.listdir(nested_dir):
        src = os.path.join(nested_dir, filename)
        dst = os.path.join(target_dir, filename)

        # å¦‚æœç›®æ ‡å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤ï¼Œé˜²æ­¢æŠ¥é”™
        if os.path.exists(dst):
            if os.path.isdir(dst): shutil.rmtree(dst)
            else: os.remove(dst)

        shutil.move(src, dst)
        print(f"  -> ç§»åŠ¨: {filename}")

    # åˆ æ‰ç©ºçš„å¥—å¨ƒå£³å­
    os.rmdir(nested_dir)
    print("âœ… æ¬å®¶å®Œæˆï¼ç»“æ„å·²ä¿®å¤ã€‚")
else:
    print("â„¹ï¸ æ²¡å‘ç°å¥—å¨ƒæ–‡ä»¶å¤¹ã€‚")
    # æ£€æŸ¥ä¸€ä¸‹æ–‡ä»¶åˆ°åº•åœ¨å“ª
    if os.path.exists(os.path.join(target_dir, "transforms_train.json")):
        print("âœ… ç¡®è®¤ï¼šjson æ–‡ä»¶å·²ç»åœ¨æ­£ç¡®ä½ç½®äº†ã€‚")
    else:
        print("âŒ ä¾ç„¶æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥å·¦ä¾§æ–‡ä»¶æ ç¡®è®¤è·¯å¾„ã€‚")

import os
import time
import threading
import shutil
import re
from google.colab import drive
from IPython import get_ipython

# 1. ç¯å¢ƒå‡†å¤‡
if not os.path.exists('/content/drive'):
    drive.mount('/content/drive')

project_dir = '/content/jax3d/jax3d/projects/mobilenerf'
if os.path.exists(project_dir):
    os.chdir(project_dir)
    os.environ['PYTHONPATH'] += ":/content/jax3d"
else:
    print(f"âŒ æ‰¾ä¸åˆ°é¡¹ç›®ç›®å½•: {project_dir}")





"""# Cell 4: Stage1 å¤‡ä»½ + Stage2 ä»£ç ä¿®å¤å…¥å£"""

# ==============================================================================
# Stage 2 å¼ºåˆ¶ä¿®å¤è„šæœ¬ (æ— è®ºå¦‚ä½•éƒ½è¦æŠŠ 0.033 å¡è¿›å»ï¼)
# ==============================================================================
import os

PROJECT_ROOT = "/content/jax3d/jax3d/projects/mobilenerf"
target_file = os.path.join(PROJECT_ROOT, 'stage2.py')
LOCAL_SAMPLES_DIR = os.path.join(PROJECT_ROOT, "samples_stage2")
# ä½ çš„ Drive è¾“å‡ºè·¯å¾„
DRIVE_OUTPUT_DIR = "/content/drive/MyDrive/Stage1_12Jan/Stage2_Result_256"

print(f"ğŸ”§ æ­£åœ¨æš´åŠ›ä¿®å¤ {target_file} ...")

with open(target_file, 'r') as f:
    lines = f.readlines()

new_lines = []
scale_injected = False

for line in lines:
    # 1. å¼ºåˆ¶ä¿®æ”¹åˆ†è¾¨ç‡ä¸º 256
    if "point_grid_size =" in line and "128" in line:
        line = "    point_grid_size = 256 # [Force 256]\n"
        print("   âœ… åˆ†è¾¨ç‡å·²å¼ºåˆ¶æ”¹ä¸º 256")

    # 2. å¼ºåˆ¶ä¿®æ”¹ Samples è·¯å¾„
    if "os.path.join(base_dir, 'samples')" in line:
        line = line.replace("os.path.join(base_dir, 'samples')", f"'{LOCAL_SAMPLES_DIR}'")
    if "os.path.join(logdir, 'samples')" in line:
        line = line.replace("os.path.join(logdir, 'samples')", f"'{LOCAL_SAMPLES_DIR}'")

    # 3. ğŸ”¥ æ ¸å¿ƒï¼šåœ¨ return ä¹‹å‰å¼ºåˆ¶æ’å…¥ Scale 0.033
    # æˆ‘ä»¬å¯»æ‰¾è¿™ä¸€è¡Œï¼Œä¸€æ—¦æ‰¾åˆ°ï¼Œå°±åœ¨å®ƒå‰é¢æ’é˜Ÿ
    if "return {'images' : images" in line and not scale_injected:
        print("   ğŸ”¥ [é‡è¦] æ­£åœ¨æ³¨å…¥ Scale 0.033 ä»£ç ...")
        # å†™å…¥ç¼©æ”¾é€»è¾‘
        new_lines.append("\n    # [FORCE INJECTED SCALE]\n")
        new_lines.append("    print('âš¡âš¡âš¡ APPLYING SCALE 0.033 âš¡âš¡âš¡')\n")
        new_lines.append("    poses = poses.at[:, :3, 3].set(poses[:, :3, 3] * 0.033)\n")
        new_lines.append(line) # æŠŠåŸæ¥çš„ return å†™å›å»
        scale_injected = True
        continue

    # 4. ä¿®å¤ Stage 1 æƒé‡è¯»å–è·¯å¾„ (é˜²æ­¢è¯»ä¸åˆ°)
    if "pickle.load" in line and "weights_stage1.pkl" in line:
        line = "    vars = pickle.load(open('weights/weights_stage1.pkl', 'rb'))\n"
        print("   âœ… æƒé‡è¯»å–è·¯å¾„å·²ä¿®æ­£")

    new_lines.append(line)

# å†™å›æ–‡ä»¶
with open(target_file, 'w') as f:
    f.writelines(new_lines)

if scale_injected:
    print("\nğŸ‰ ä¿®å¤æˆåŠŸï¼0.033 ç¼©æ”¾ä»£ç å·²å¼ºåˆ¶å†™å…¥ã€‚")
else:
    print("\nâŒ ä¸¥é‡é”™è¯¯ï¼šæ²¡æ‰¾åˆ°æ³¨å…¥ç‚¹ï¼è¯·æ£€æŸ¥ stage2.py å†…å®¹ã€‚")

"""# Cell 5: ç®€æ˜“ç‰ˆ Stage1 å¯åŠ¨ï¼ˆå¤‡ä»½ + è®­ç»ƒï¼‰"""

# ==============================================================================
# ğŸ›¡ï¸ Stage1 Step 1: å¼ºç›—å¤‡ä»½è„šæœ¬
# ==============================================================================
local_checkpoints = "checkpoints"
local_weights = "weights"
local_samples = "samples"

drive_root = "/content/drive/MyDrive/Stage1_12Jan"
drive_checkpoints = os.path.join(drive_root, "checkpoints")
drive_weights = os.path.join(drive_root, "weights")
drive_samples = os.path.join(drive_root, "samples")

def background_backup():
    print("ğŸ›¡ï¸ åå°å¤‡ä»½æœåŠ¡å·²å¯åŠ¨...")
    while True:
        try:
            if os.path.exists(local_checkpoints):
                if not os.path.exists(drive_checkpoints): os.makedirs(drive_checkpoints)
                os.system(f"cp -ru '{local_checkpoints}/.' '{drive_checkpoints}/'")
            if os.path.exists(local_weights):
                if not os.path.exists(drive_weights): os.makedirs(drive_weights)
                os.system(f"cp -ru '{local_weights}/.' '{drive_weights}/'")
            if os.path.exists(local_samples):
                if not os.path.exists(drive_samples): os.makedirs(drive_samples)
                os.system(f"cp -ru '{local_samples}/.' '{drive_samples}/'")
        except:
            pass
        time.sleep(30)

t = threading.Thread(target=background_backup)
t.daemon = True
t.start()

# ==============================================================================
# ğŸš€ Stage1 Step 2: å¯åŠ¨è®­ç»ƒ
# ==============================================================================
print("ğŸš€ å¯åŠ¨è®­ç»ƒ...")

cmd = """
source activate mobilenerf && export MPLBACKEND=Agg && python stage1.py \
  --gin_configs=configs/360.gin \
  --gin_bindings="Config.dataset_loader='blender'" \
  --gin_bindings="Config.batch_size=4096" \
  --gin_bindings="Config.data_dir='/content/jax3d/jax3d/projects/mobilenerf/data/custom/MyNeRFData'" \
  --gin_bindings="Config.checkpoint_dir='/content/jax3d/jax3d/projects/mobilenerf/checkpoints'" \
  --gin_bindings="Config.render_every=1000" \
  --gin_bindings="Config.save_every=2000" \
  --logtostderr
"""

get_ipython().system(cmd)

"""# Cell 6: Stage2 é€‚é… .pkl å­˜æ¡£ + Scale 0.033"""

# ==============================================================================
# ğŸ›¡ï¸ Stage 2 å¤åˆ»ä¿®æ­£ç‰ˆ (ä¿®å¤è·¯å¾„ + Scale 0.033 + Res 256)
# ==============================================================================
import os
import re
import pickle
import shutil
import glob
from google.colab import drive
from IPython import get_ipython

# --- 1. è·¯å¾„ä¸å‚æ•°é…ç½® ---
# Drive æºå¤´ (Stage 1 æƒé‡)
DRIVE_SOURCE_PKL_DIR = "/content/drive/MyDrive/Stage1_12Jan/weights"
# Drive è¾“å‡º (Stage 2 ç»“æœ) - ç›´æ¥å­˜è¿™é‡Œé˜²æ–­è¿
DRIVE_OUTPUT_DIR = "/content/drive/MyDrive/Stage1_12Jan/Stage2_Result_256"

# æœ¬åœ°è·¯å¾„
PROJECT_ROOT = "/content/jax3d/jax3d/projects/mobilenerf"
LOCAL_WEIGHTS_DIR = os.path.join(PROJECT_ROOT, "weights")
LOCAL_SAMPLES_DIR = os.path.join(PROJECT_ROOT, "samples_stage2")

# å…³é”®å‚æ•°
TARGET_SCALE = 0.033
TARGET_GRID = 256

# ==============================================================================
# Stage2 [Step 1] ç¯å¢ƒå‡†å¤‡
# ==============================================================================
print("ğŸšš [1/4] ç¯å¢ƒå‡†å¤‡ä¸­...")

if not os.path.exists('/content/drive'): drive.mount('/content/drive')
if not os.path.exists(LOCAL_WEIGHTS_DIR): os.makedirs(LOCAL_WEIGHTS_DIR)
if not os.path.exists(LOCAL_SAMPLES_DIR): os.makedirs(LOCAL_SAMPLES_DIR)
if not os.path.exists(DRIVE_OUTPUT_DIR): os.makedirs(DRIVE_OUTPUT_DIR)

# æ¬è¿æƒé‡ (ç¡®ä¿ weights/weights_stage1.pkl å­˜åœ¨)
print(f"    ğŸ“¥ æ­£åœ¨æŸ¥æ‰¾ Stage 1 æƒé‡...")
pkl_files = glob.glob(os.path.join(DRIVE_SOURCE_PKL_DIR, "*.pkl"))
if not pkl_files:
    pkl_files = glob.glob(os.path.join(os.path.dirname(DRIVE_SOURCE_PKL_DIR), "*.pkl"))

if pkl_files:
    pkl_files.sort(key=os.path.getmtime)
    target_pkl = pkl_files[-1]
    shutil.copy2(target_pkl, os.path.join(LOCAL_WEIGHTS_DIR, "weights_stage1.pkl"))
    print(f"      -> å·²å°±ä½: {os.path.basename(target_pkl)}")
else:
    print("âŒ é”™è¯¯ï¼šDrive é‡Œæ²¡æ‰¾åˆ° .pkl æ–‡ä»¶ï¼")
    assert False

# ==============================================================================
# Stage2 [Step 2] ä»£ç æ‰‹æœ¯ï¼ˆè·¯å¾„ä¸é‡‡æ ·é…ç½®ï¼‰
# ==============================================================================
target_file = os.path.join(PROJECT_ROOT, 'stage2.py')
print(f"ğŸ’‰ [2/4] ä¿®æ”¹ä»£ç ...")

with open(target_file, 'r') as f:
    content = f.read()

# 1. åŸºç¡€ä¿®å¤
content = re.sub(r'object_name = "chair"', 'object_name = "MyNeRFData"', content)
content = re.sub(r'scene_dir = "datasets/nerf_synthetic/.*?\+object_name', 'scene_dir = "data/custom/"+object_name', content)
content = content.replace("import matplotlib.pyplot as plt", "import matplotlib; matplotlib.use('Agg'); import matplotlib.pyplot as plt")

# 3. ä¿®æ­£ Samples è¾“å‡ºè·¯å¾„
content = content.replace("os.path.join(base_dir, 'samples')", f"'{LOCAL_SAMPLES_DIR}'")
content = content.replace("os.path.join(logdir, 'samples')", f"'{LOCAL_SAMPLES_DIR}'")

# 4. [å…³é”®ä¿®æ”¹] å‡çº§åˆ†è¾¨ç‡åˆ° 256
if "point_grid_size = 128" in content:
    content = content.replace("point_grid_size = 128", f"point_grid_size = {TARGET_GRID} # [A100 Force]")
    print(f"    âœ… åˆ†è¾¨ç‡å·²ä¿®æ”¹ä¸º {TARGET_GRID}")

# 5. [å…³é”®ä¿®æ”¹] æ³¨å…¥ Scale 0.033
original_return = "return {'images' : images, 'c2w' : poses, 'hwf' : hwf}"
if "poses[:, :3, 3] * " + str(TARGET_SCALE) not in content:
    injection_code = f"""
    # [Auto-Scale Injection]
    print("âš¡ Applying Scale {TARGET_SCALE}...")
    poses = poses.at[:, :3, 3].set(poses[:, :3, 3] * {TARGET_SCALE})
    {original_return}
    """
    content = content.replace(original_return, injection_code)
    print(f"    âœ… Scale {TARGET_SCALE} æ³¨å…¥ä»£ç å·²æ’å…¥")

# 6. ä¿®å¤ Stage 1 æƒé‡è¯»å– (ç¡®ä¿è¯» weights/weights_stage1.pkl)
# åŸä»£ç å¯èƒ½æ˜¯ pickle.load(open(weights_dir+"/"+"weights_stage1.pkl", "rb"))
# æˆ‘ä»¬ç›´æ¥ç¡¬æ”¹
if 'weights_stage1.pkl' in content:
    # è¿™é‡Œçš„æ­£åˆ™ç¨å¾®å®½æ³›ä¸€ç‚¹ï¼ŒåŒ¹é… open(...) é‡Œçš„å†…å®¹
    content = re.sub(r'open\(.*?"weights_stage1\.pkl".*?,', 'open("weights/weights_stage1.pkl",', content)

with open(target_file, 'w') as f:
    f.write(content)

# ==============================================================================
# Stage2 [Step 3] å¯åŠ¨ Stage 2
# ==============================================================================
print(f"\nğŸš€ [3/4] å¯åŠ¨ Stage 2 ...")
print(f"    ğŸ’¾ å­˜æ¡£å°†ç›´æ¥å†™å…¥: {DRIVE_OUTPUT_DIR}")

os.chdir(PROJECT_ROOT)

# å¯åŠ¨å‘½ä»¤
cmd = f"""
source activate mobilenerf && export MPLBACKEND=Agg && python stage2.py \
  --gin_configs=configs/360.gin \
  --gin_bindings="Config.dataset_loader='blender'" \
  --gin_bindings="Config.batch_size=2048" \
  --gin_bindings="Config.data_dir='data/custom/MyNeRFData'" \
  --gin_bindings="Config.checkpoint_dir='{DRIVE_OUTPUT_DIR}'" \
  --logtostderr
"""

get_ipython().system(cmd)

# ==============================================================================
# Stage2 [Step 4] é¢å¤–å¤‡ä»½ Samples
# ==============================================================================
print("\nğŸ“¦ [4/4] å¤‡ä»½ Samples å›¾ç‰‡...")
if os.path.exists(LOCAL_SAMPLES_DIR):
    drive_sample_dest = DRIVE_OUTPUT_DIR + "_samples"
    if not os.path.exists(drive_sample_dest): os.makedirs(drive_sample_dest)
    os.system(f"cp -r '{LOCAL_SAMPLES_DIR}/.' '{drive_sample_dest}/'")

"""# Cell 7: Stage3 æå– Mesh ä¸çº¹ç†ï¼ˆé€‚é… Drive è¯»å– + ç‹¬ç«‹è¾“å‡ºï¼‰"""

# ==============================================================================
# ğŸ›ï¸ Stage 3 æœ€ç»ˆç‰ˆï¼ˆæ¥åŠ›æƒé‡å¯¼å‡º Mesh + çº¹ç†ï¼‰
# ==============================================================================
import os
import re
import shutil
from google.colab import drive
from IPython import get_ipython

# --- 1. è·¯å¾„é…ç½® ---
PROJECT_ROOT = "/content/jax3d/jax3d/projects/mobilenerf"

# å…³é”®ï¼šè¯»å–åˆšæ‰ Stage 2 åˆšç”Ÿæˆçš„æ–°æƒé‡ (æœ¬åœ°)
LOCAL_S2_WEIGHTS_READ = os.path.join(PROJECT_ROOT, "weights")

# è¾“å‡ºè·¯å¾„
LOCAL_S3_OBJ_SAVE = os.path.join(PROJECT_ROOT, "obj_stage3_256")
LOCAL_S3_SAMPLES_SAVE = os.path.join(PROJECT_ROOT, "samples_stage3_256")

# Drive å¤‡ä»½è·¯å¾„
DRIVE_FINAL_EXPORT = "/content/drive/MyDrive/Stage1_12Jan/Final_Sponza_256"

# ================= Step 1: ç¯å¢ƒå‡†å¤‡ & æƒé‡æ£€æŸ¥ =================
print("ğŸšš [1/4] æ­£åœ¨æ£€æŸ¥æƒé‡...")

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
if not os.path.exists(LOCAL_S3_OBJ_SAVE): os.makedirs(LOCAL_S3_OBJ_SAVE)
if not os.path.exists(LOCAL_S3_SAMPLES_SAVE): os.makedirs(LOCAL_S3_SAMPLES_SAVE)

# æ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰åˆšæ‰ Stage 2 è·‘å‡ºæ¥çš„æƒé‡
if not os.path.exists(LOCAL_S2_WEIGHTS_READ):
    print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° Stage 2 çš„è¾“å‡ºç›®å½•: {LOCAL_S2_WEIGHTS_READ}")
    print("   è¯·ç¡®ä¿åˆšæ‰çš„ Stage 2 å·²ç»æˆåŠŸè·‘å®Œï¼")
    assert False

# æ‰¾æœ€æ–°çš„æƒé‡æ–‡ä»¶
pkl_files = [f for f in os.listdir(LOCAL_S2_WEIGHTS_READ) if f.endswith(".pkl")]
if not pkl_files:
    print(f"âŒ é”™è¯¯ï¼šåœ¨ {LOCAL_S2_WEIGHTS_READ} é‡Œæ²¡æ‰¾åˆ° .pkl æ–‡ä»¶ï¼")
    assert False

# æ’åºæ‰¾åˆ°æœ€æ–°çš„ (é€šå¸¸æ˜¯ checkpoint_20000 è¿™ç§)
pkl_files.sort(key=lambda x: int(re.search(r'\d+', x).group()) if re.search(r'\d+', x) else 0)
target_pkl = pkl_files[-1]
print(f"   âœ… é”å®š Stage 2 æƒé‡: {target_pkl}")

# âš ï¸ å…³é”®åŠ¨ä½œï¼šæŠŠè¿™ä¸ªæ–‡ä»¶å¤åˆ¶ä¸€ä»½å¹¶åœ¨åŸåœ°æ”¹åä¸º 'weights_stage2_1.pkl'
# å› ä¸º Stage 3 ä»£ç é‡Œé€šå¸¸å†™æ­»è¯»è¿™ä¸ªåå­—ï¼Œæˆ–è€…è¯» list çš„æœ€åä¸€ä¸ª
# ä¸ºäº†ç¨³å¦¥ï¼Œæˆ‘ä»¬æ‰‹åŠ¨å¸®å®ƒå‡†å¤‡å¥½
dest_pkl = os.path.join(LOCAL_S2_WEIGHTS_READ, "weights_stage2_1.pkl")
shutil.copy2(os.path.join(LOCAL_S2_WEIGHTS_READ, target_pkl), dest_pkl)
print(f"   ğŸ“¦ å·²å‡†å¤‡å¥½æ ‡å‡†å‘½åæƒé‡: weights_stage2_1.pkl")


# ================= Step 2: ä»£ç ç²¾å‡†æ‰‹æœ¯ =================
print("\nğŸ’‰ [2/4] ä¿®æ”¹ Stage 3 ä»£ç  (åˆ†è¾¨ç‡256 + ç›’å­0.7)...")

target_file = os.path.join(PROJECT_ROOT, 'stage3.py')
with open(target_file, 'r') as f:
    content = f.read()

# A. è·¯å¾„ä¿®å¤
content = content.replace('object_name = "chair"', 'object_name = "MyNeRFData"')
content = content.replace('scene_dir = "datasets/nerf_synthetic/"+object_name', 'scene_dir = "data/custom/"+object_name')
# æŒ‡å‘æˆ‘ä»¬åˆšå‡†å¤‡å¥½çš„æœ¬åœ°ç›®å½•
content = content.replace('weights_dir = "weights"', f'weights_dir = "{LOCAL_S2_WEIGHTS_READ}"')
content = content.replace('obj_save_dir = "obj"', f'obj_save_dir = "{LOCAL_S3_OBJ_SAVE}"')
content = content.replace('samples_dir = "samples"', f'samples_dir = "{LOCAL_S3_SAMPLES_SAVE}"')

# B. ğŸ”¥ å…³é”®åŒæ­¥ï¼šåˆ†è¾¨ç‡å¿…é¡»æ˜¯ 256 (åŒ¹é… Stage 2)
if "point_grid_size = 128" in content:
    content = content.replace("point_grid_size = 128", "point_grid_size = 256 # [MATCH STAGE 2]")
    print("   âœ… åˆ†è¾¨ç‡å·²åŒæ­¥ä¸º 256 (åŒ¹é…æƒé‡)")
elif "point_grid_size = 256" in content:
    print("   âœ… åˆ†è¾¨ç‡ä¿æŒ 256")

# C. ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šç›’å­å¤§å° Scale 0.7 (é€‚é… 1.22m Sponza)
# 1.4m çš„ç›’å­è£… 1.22m çš„ç‰©ä½“ï¼Œåˆ©ç”¨ç‡æé«˜
if "scene_grid_scale = 1.2" in content:
    content = content.replace("scene_grid_scale = 1.2", "scene_grid_scale = 0.7 # [Fit Sponza]")
    print("   âœ… æ•è·æ¡†ä¼˜åŒ–ä¸º 0.7 (ç´§å‡‘é«˜ç²¾)")
elif "scene_grid_scale = 0.2" in content:
    content = content.replace("scene_grid_scale = 0.2", "scene_grid_scale = 0.7 # [Fit Sponza]")
    print("   âœ… æ•è·æ¡†ä¿®æ­£ä¸º 0.7")

# D. JAX Scale æ³¨å…¥ (ä¿æŒ 0.033)
if "poses = np.stack(cams, axis=0)" in content:
    content = content.replace("poses[:, :3, 3] *= 0.033", "")
    if ".at[" not in content:
        content = content.replace(
            "poses = np.stack(cams, axis=0)",
            "poses = np.stack(cams, axis=0)\n    poses = poses.at[:, :3, 3].set(poses[:, :3, 3] * 0.033) # [JAX Scale]"
        )

# E. ç§»é™¤ Testing (åŠ é€Ÿ)
if 'print("Testing")' in content:
    content = content.replace('print("Testing")', '# print("Testing")')
    content = content.replace('for i in tqdm(range(len(data[\'test\'][\'images\']))):', 'for i in []:\n  pass')
    content = content.replace('for p in tqdm(render_poses):', 'for p in []:\n  pass')

with open(target_file, 'w') as f:
    f.write(content)

# ================= Step 3: å¯åŠ¨ =================
print("\nğŸš€ [3/4] å¯åŠ¨ Stage 3 (High Res Export)...")
os.chdir(PROJECT_ROOT)
cmd = "source activate mobilenerf && export MPLBACKEND=Agg && python stage3.py"

try:
    get_ipython().system(cmd)
    print("\nğŸ‰ Stage 3 æå–ç»“æŸï¼")
except Exception as e:
    print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")

# ================= Step 4: å¤‡ä»½ =================
print("\nğŸ“¦ [4/4] å¤‡ä»½æœ€ç»ˆç»“æœåˆ° Drive...")
if not os.path.exists('/content/drive'): drive.mount('/content/drive')
if not os.path.exists(DRIVE_FINAL_EXPORT): os.makedirs(DRIVE_FINAL_EXPORT)

if os.path.exists(LOCAL_S3_OBJ_SAVE):
    print(f"   -> æ­£åœ¨å¤‡ä»½ OBJ/GLB åˆ°: {DRIVE_FINAL_EXPORT}")
    os.system(f"cp -r '{LOCAL_S3_OBJ_SAVE}/.' '{DRIVE_FINAL_EXPORT}/'")

    # å¤‡ä»½ Phone ç‰ˆ
    phone_src = LOCAL_S3_OBJ_SAVE + "_phone"
    if os.path.exists(phone_src):
        phone_dst = os.path.join(DRIVE_FINAL_EXPORT, "obj_phone")
        if not os.path.exists(phone_dst): os.makedirs(phone_dst)
        os.system(f"cp -r '{phone_src}/.' '{phone_dst}/'")

print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼é«˜ç²¾åº¦ Sponza å·²ä¿å­˜è‡³: {DRIVE_FINAL_EXPORT}")

"""# Cell 8: Hybrid Workflow ç¯å¢ƒé…ç½®ï¼ˆåŸºäº Colab é»˜è®¤ç¯å¢ƒï¼‰"""

643â†’print("\nğŸš€ [Hybrid Env] é…ç½® Torch + PyTorch3D ç¯å¢ƒï¼ˆä½¿ç”¨ Colab é»˜è®¤ Pythonï¼‰...")
644â†’
645â†’!pip install --upgrade pip
646â†’!pip install "numpy<2"
647â†’!pip install torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0+cu118 -f https://download.pytorch.org/whl/torch_stable.html

"""# Cell 8-UV: 01_preprocess_raster ä¸“ç”¨ç¯å¢ƒï¼ˆç‹¬ç«‹ Conda + PyTorch3Dï¼‰"""

print("\nğŸš€ [Hybrid UV Env] ä½¿ç”¨ Conda é…ç½® 01_preprocess_raster ä¸“ç”¨ç¯å¢ƒ...")

!conda create -n hybrid3d_uv python=3.11 -y
!source activate hybrid3d_uv && conda install -y pytorch=2.3.1 torchvision=0.18.1 torchaudio=2.3.1 pytorch-cuda=11.8 -c pytorch -c nvidia -c conda-forge
!source activate hybrid3d_uv && conda install -y pytorch3d=0.7.8 -c pytorch3d -c pytorch -c nvidia -c conda-forge

"""# Cell 9: Hybrid Pipeline Step 1 - é¢„è®¡ç®— UV (PyTorch3D)"""

import os
from IPython import get_ipython
from google.colab import drive
import numpy as np

PROJECT_ROOT_HYBRID = "/content/jax3d/jax3d/projects/mobilenerf"
DRIVE_HYBRID_ROOT = "/content/drive/MyDrive/Hybrid_Pipeline"

HYBRID_DATA_ROOT = "data/custom/MyNeRFData"
HYBRID_OBJ_NAME = "sponza_gt.obj"
HYBRID_TRANSFORMS = "transforms_train.json"
HYBRID_UV_OUTPUT = "uv_lookup.npz"
HYBRID_ENV_PYTHON = "/usr/local/envs/hybrid3d_uv/bin/python"

HYBRID_IMAGE_DOWNSCALE = 1

print("\nğŸš€ [Hybrid 1/2] é¢„è®¡ç®— UV æ˜ å°„ (PyTorch3D)...")
print(f"   -> å›¾åƒ / UV åˆ†è¾¨ç‡ç¼©æ”¾å€æ•°: {HYBRID_IMAGE_DOWNSCALE}ï¼ˆ1 è¡¨ç¤ºä¸è®­ç»ƒ PNG ä¸€è‡´ï¼‰")

if not os.path.exists("/content/drive"):
    drive.mount("/content/drive")

if not os.path.exists(DRIVE_HYBRID_ROOT):
    os.makedirs(DRIVE_HYBRID_ROOT)
    print(f"ğŸ“ å·²åˆ›å»º Hybrid ç»“æœç›®å½•: {DRIVE_HYBRID_ROOT}")

if os.path.exists(PROJECT_ROOT_HYBRID):
    os.chdir(PROJECT_ROOT_HYBRID)
    cmd = f"""
export MPLBACKEND=Agg && {HYBRID_ENV_PYTHON} 01_preprocess_raster.py \
  --data_root='{HYBRID_DATA_ROOT}' \
  --obj_name='{HYBRID_OBJ_NAME}' \
  --transforms='{HYBRID_TRANSFORMS}' \
  --output='{HYBRID_UV_OUTPUT}' \
  --downscale={HYBRID_IMAGE_DOWNSCALE}
"""
    get_ipython().system(cmd)

    uv_path = os.path.join(PROJECT_ROOT_HYBRID, HYBRID_DATA_ROOT, HYBRID_UV_OUTPUT)
    if os.path.exists(uv_path):
        data = np.load(uv_path, allow_pickle=True)
        uv_shape = data["uv"].shape
        print(f"âœ… UV æ˜ å°„ç”Ÿæˆå®Œæˆï¼Œå½¢çŠ¶: {uv_shape}")

        if not os.path.exists(DRIVE_HYBRID_ROOT):
            os.makedirs(DRIVE_HYBRID_ROOT)
        os.system(f"cp '{uv_path}' '{DRIVE_HYBRID_ROOT}/'")
        print(f"âœ… UV æ˜ å°„å·²å¤‡ä»½åˆ°: {DRIVE_HYBRID_ROOT}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ° uv_lookup.npzï¼Œè¯·æ£€æŸ¥æœ¬åœ°è¿è¡Œç»“æœ")
else:
    print(f"âŒ æ‰¾ä¸åˆ°é¡¹ç›®ç›®å½•: {PROJECT_ROOT_HYBRID}")

"""# Cell 11: Hybrid Pipeline Step 2 - è®­ç»ƒ Hybrid Texture + MLP"""

import os
import time
import threading
from IPython import get_ipython
from google.colab import drive

PROJECT_ROOT_HYBRID = "/content/jax3d/jax3d/projects/mobilenerf"
DRIVE_HYBRID_ROOT = "/content/drive/MyDrive/Hybrid_Pipeline"

HYBRID_DATA_ROOT_TRAIN = "data/custom/MyNeRFData_1k"
HYBRID_UV_PATH_TRAIN = os.path.join(HYBRID_DATA_ROOT_TRAIN, "uv_lookup.npz")

HYBRID_TEXTURE_SIZE = 512
HYBRID_BATCH_SIZE = 1024
HYBRID_NUM_ITERS = 150000
HYBRID_LR = 3e-4
HYBRID_DOWNSCALE_TRAIN = 1

HYBRID_CHECKPOINT_PATH = "weights/hybrid_texture_mlp.pth"
HYBRID_ENV_PYTHON = "python"

print("\nğŸš€ [Hybrid 2/2] å¯åŠ¨ Hybrid Texture + MLP è®­ç»ƒ...")

if not os.path.exists("/content/drive"):
    drive.mount("/content/drive")

if not os.path.exists(DRIVE_HYBRID_ROOT):
    os.makedirs(DRIVE_HYBRID_ROOT)

local_weights = os.path.join(PROJECT_ROOT_HYBRID, "weights")
local_samples = os.path.join(PROJECT_ROOT_HYBRID, "samples")
dst_weights = os.path.join(DRIVE_HYBRID_ROOT, "weights")
dst_samples = os.path.join(DRIVE_HYBRID_ROOT, "samples")

def hybrid_background_backup():
    while True:
        try:
            if os.path.exists(local_weights):
                if not os.path.exists(dst_weights):
                    os.makedirs(dst_weights)
                os.system(f"cp -ru '{local_weights}/.' '{dst_weights}/'")
            if os.path.exists(local_samples):
                if not os.path.exists(dst_samples):
                    os.makedirs(dst_samples)
                os.system(f"cp -ru '{local_samples}/.' '{dst_samples}/'")
        except:
            pass
        time.sleep(60)

t = threading.Thread(target=hybrid_background_backup)
t.daemon = True
t.start()

local_uv_path = os.path.join(PROJECT_ROOT_HYBRID, HYBRID_UV_PATH_TRAIN)
drive_uv_path = os.path.join(DRIVE_HYBRID_ROOT, os.path.basename(HYBRID_UV_PATH_TRAIN))

if not os.path.exists(local_uv_path) and os.path.exists(drive_uv_path):
    os.makedirs(os.path.dirname(local_uv_path), exist_ok=True)
    os.system(f"cp '{drive_uv_path}' '{local_uv_path}'")
    print(f"ğŸ”„ å·²ä» Drive æ¢å¤ uv_lookup.npz åˆ°æœ¬åœ°: {local_uv_path}")

if os.path.exists(PROJECT_ROOT_HYBRID):
    os.chdir(PROJECT_ROOT_HYBRID)
    cmd = f"""
export MPLBACKEND=Agg && {HYBRID_ENV_PYTHON} 02_train_hybrid.py \
  --data_root='{HYBRID_DATA_ROOT_TRAIN}' \
  --uv_path='{HYBRID_UV_PATH_TRAIN}' \
  --texture_size={HYBRID_TEXTURE_SIZE} \
  --batch_size={HYBRID_BATCH_SIZE} \
  --num_iters={HYBRID_NUM_ITERS} \
  --lr={HYBRID_LR} \
  --device='auto' \
  --downscale={HYBRID_DOWNSCALE_TRAIN} \
  --checkpoint='{HYBRID_CHECKPOINT_PATH}'
"""
    get_ipython().system(cmd)

    print("\nğŸ“¦ æ­£åœ¨å¤‡ä»½ Hybrid è®­ç»ƒç»“æœåˆ° Drive...")
    if not os.path.exists(DRIVE_HYBRID_ROOT):
        os.makedirs(DRIVE_HYBRID_ROOT)

    local_weights = os.path.join(PROJECT_ROOT_HYBRID, "weights")
    local_samples = os.path.join(PROJECT_ROOT_HYBRID, "samples")

    if os.path.exists(local_weights):
        dst_weights = os.path.join(DRIVE_HYBRID_ROOT, "weights")
        if not os.path.exists(dst_weights):
            os.makedirs(dst_weights)
        os.system(f"cp -ru '{local_weights}/.' '{dst_weights}/'")

    if os.path.exists(local_samples):
        dst_samples = os.path.join(DRIVE_HYBRID_ROOT, "samples")
        if not os.path.exists(dst_samples):
            os.makedirs(dst_samples)
        os.system(f"cp -ru '{local_samples}/.' '{dst_samples}/'")

    print(f"\nâœ… Hybrid è®­ç»ƒç»“æœå·²ä¿å­˜è‡³: {DRIVE_HYBRID_ROOT}")
else:
    print(f"âŒ æ‰¾ä¸åˆ°é¡¹ç›®ç›®å½•: {PROJECT_ROOT_HYBRID}")
