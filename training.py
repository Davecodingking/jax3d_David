# -*- coding: utf-8 -*-
"""training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zebqJlzfvhUNkDAkTDCtHpAvCtYDVgY5

# å¯é€‰å‚è€ƒå—: å®‰è£… Conda + æ„å»º Python 3.9 ç¯å¢ƒ + å…‹éš†å®˜æ–¹ jax3dï¼ˆä¸€èˆ¬å¯ä»¥è·³è¿‡ï¼‰
# è¯´æ˜: ä»…å½“ä½ éœ€è¦å¯¹ç…§å®˜æ–¹åŸç‰ˆä»“åº“æ—¶å†è¿è¡Œè¿™ä¸€å—ï¼›
#      å¸¸è§„è®­ç»ƒå»ºè®®ç›´æ¥ä»ä¸‹æ–¹ Cell 1 å¼€å§‹ï¼Œä½¿ç”¨ jax3d_David ä»“åº“ã€‚
"""

# -*- coding: utf-8 -*-
import os

print("â³ æ­£åœ¨å®‰è£… Conda (å¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿ)...")
!pip install -q condacolab
import condacolab
condacolab.install()

import time
time.sleep(5) # ç»™å®ƒä¸€ç‚¹æ—¶é—´ååº”
print("âœ… Conda å®‰è£…å®Œæˆï¼æ­£åœ¨é…ç½® Python 3.9 ç¯å¢ƒ...")

# åˆ›å»ºç¯å¢ƒå¹¶é”æ­» JAX ç‰ˆæœ¬ (0.3.25)
!conda create -n mobilenerf python=3.9 -y
!source activate mobilenerf && conda install -c conda-forge cudatoolkit=11.8 cudnn=8.8 -y
# ä½¿ç”¨ --no-deps é˜²æ­¢ pip è‡ªåŠ¨å‡çº§ JAX
!source activate mobilenerf && pip install "jax[cuda11_pip]==0.3.25" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html --no-deps
# æ‰‹åŠ¨è¡¥é½ JAX ä¾èµ–
!source activate mobilenerf && pip install "flax==0.5.3" scipy "optax==0.1.4" "chex==0.1.5" "absl-py" --no-deps
# å®‰è£…å…¶ä»–å·¥å…·
!source activate mobilenerf && pip install tqdm opencv-python-headless matplotlib gin-config msgpack typing-extensions opt_einsum toolz rich PyYAML numpy==1.23.5

# ä¸‹è½½ä»£ç 
if not os.path.exists('/content/jax3d'):
    !git clone https://github.com/google-research/jax3d.git

print("âœ… ç¯å¢ƒæ­å»ºå®Œæ¯•ï¼JAX ç‰ˆæœ¬å·²é”æ­»ä¸º 0.3.25")

"""# Cell 1: ä¸€é”®é…ç½®ç¯å¢ƒ + æ‹‰å– Dave çš„ä¿®å¤ç‰ˆä»£ç """

# ==============================================================================
# Cell 1: ä¸€é”®é…ç½®ç¯å¢ƒ + æ‹‰å– Dave çš„ä¿®å¤ç‰ˆä»£ç 
# ==============================================================================
import os
import time
import shutil

# --- 1. å®‰è£…åŸºç¡€ç¯å¢ƒ (Conda) ---
print("â³ æ­£åœ¨å®‰è£… Conda...")
try:
    import condacolab
except ImportError:
    !pip install -q condacolab
    import condacolab
condacolab.install()
time.sleep(5)

print("âœ… Conda å°±ç»ªï¼é…ç½® Python 3.9 + JAX...")

# --- 2. é…ç½® Python ç¯å¢ƒ (é”æ­»ç‰ˆæœ¬) ---
!conda create -n mobilenerf python=3.9 -y
# å®‰è£… CUDA, JAX, Flax (å¿…é¡»ä¸¥æ ¼åŒ¹é…)
!source activate mobilenerf && conda install -c conda-forge cudatoolkit=11.8 cudnn=8.8 -y
!source activate mobilenerf && pip install "jax[cuda11_pip]==0.3.25" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html --no-deps
!source activate mobilenerf && pip install "flax==0.5.3" scipy "optax==0.1.4" "chex==0.1.5" "absl-py" --no-deps
!source activate mobilenerf && pip install tqdm opencv-python-headless matplotlib gin-config msgpack typing-extensions opt_einsum toolz rich PyYAML numpy==1.23.5


print("âœ… è¿è¡Œç¯å¢ƒæ­å»ºå®Œæ¯•ï¼")

# --- 3. æ‹‰å–ä½ çš„ GitHub ä»£ç  (jax3d_David) ---
# ä½ çš„ä»“åº“åœ°å€
MY_REPO = "https://github.com/Davecodingking/jax3d_David.git"
TARGET_DIR = "/content/jax3d"

print(f"ğŸš€ æ­£åœ¨æ‹‰å–ä½ çš„ä»£ç : {MY_REPO}")

# æ¸…ç†æ—§ç›®å½•
if os.path.exists(TARGET_DIR): shutil.rmtree(TARGET_DIR)
if os.path.exists("/content/jax3d_David"): shutil.rmtree("/content/jax3d_David")

# å…‹éš†ä»“åº“
!git clone {MY_REPO}

# ç»“æ„ä¿®æ­£: æŠŠ jax3d_David æ”¹åä¸º jax3d (Python æ‰èƒ½è¯†åˆ«)
if os.path.exists("/content/jax3d_David"):
    shutil.move("/content/jax3d_David", TARGET_DIR)
    print("âœ… ä»£ç å·²å°±ä½ (jax3d_David -> jax3d)")
else:
    print("âŒ å…‹éš†å¤±è´¥ï¼Œè¯·æ£€æŸ¥ GitHub ä»“åº“æ˜¯å¦ä¸ºç©ºæˆ–åœ°å€é”™è¯¯ã€‚")

print("ğŸ‰ å‡†å¤‡å°±ç»ªï¼è¯·ä¸Šä¼ æ•°æ®åŒ… MyNeRFData.zip å¹¶è¿è¡Œä¸‹ä¸€æ­¥ã€‚")

"""# Cell 2: æ‰“åŒ…å½“å‰ jax3d ä»“åº“ï¼ˆå¯é€‰ï¼‰"""

import shutil
import os
from google.colab import files

# 1. å®šä¹‰æ‰“åŒ…ç›®æ ‡ï¼šæ•´ä¸ª jax3d ä»“åº“ (åŒ…å«ä¿®å¥½çš„ mobilenerf)
source_dir = '/content/jax3d'
output_filename = '/content/jax3d_fixed_final'

print(f"ğŸ“¦ æ­£åœ¨æ‰“åŒ…ä¿®å¤åçš„ä»£ç åº“: {source_dir} ...")
print("   (è¿™åŒ…å«äº† Scale=0.033, No-Gamma, RGB-Fix çš„æ‰€æœ‰ä¿®æ”¹)")

# 2. å‹ç¼©
shutil.make_archive(output_filename, 'zip', source_dir)

print(f"âœ… æ‰“åŒ…å®Œæˆ: {output_filename}.zip")
print("â¬‡ï¸ è¯·åœ¨å·¦ä¾§æ–‡ä»¶æ æ‰¾åˆ° 'jax3d_fixed_final.zip'ï¼Œå³é”®ä¸‹è½½å¹¶å¦¥å–„ä¿å­˜ï¼")
# files.download(output_filename + '.zip') # ä½ å¯ä»¥æ‰‹åŠ¨å–æ¶ˆæ³¨é‡Šè®©å®ƒè‡ªåŠ¨ä¸‹è½½

# --- 3. æ‹‰å–ä½ çš„ GitHub ä»£ç  (jax3d_David) ---
# ä½ çš„ä»“åº“åœ°å€
MY_REPO = "https://github.com/Davecodingking/jax3d_David.git"
TARGET_DIR = "/content/jax3d"

print(f"ğŸš€ æ­£åœ¨æ‹‰å–ä½ çš„ä»£ç : {MY_REPO}")

# æ¸…ç†æ—§ç›®å½•
if os.path.exists(TARGET_DIR): shutil.rmtree(TARGET_DIR)
if os.path.exists("/content/jax3d_David"): shutil.rmtree("/content/jax3d_David")

# å…‹éš†ä»“åº“
!git clone {MY_REPO}

# ç»“æ„ä¿®æ­£: æŠŠ jax3d_David æ”¹åä¸º jax3d (Python æ‰èƒ½è¯†åˆ«)
if os.path.exists("/content/jax3d_David"):
    shutil.move("/content/jax3d_David", TARGET_DIR)
    print("âœ… ä»£ç å·²å°±ä½ (jax3d_David -> jax3d)")
else:
    print("âŒ å…‹éš†å¤±è´¥ï¼Œè¯·æ£€æŸ¥ GitHub ä»“åº“æ˜¯å¦ä¸ºç©ºæˆ–åœ°å€é”™è¯¯ã€‚")

print("ğŸ‰ å‡†å¤‡å°±ç»ªï¼è¯·ä¸Šä¼ æ•°æ®åŒ… MyNeRFData.zip å¹¶è¿è¡Œä¸‹ä¸€æ­¥ã€‚")

"""# Cell 2-Drive: ä» Google Drive å¤åˆ¶ MyNeRFData.zipï¼ˆå¯é€‰ï¼‰"""

"""# Cell 2-Drive: ä» Google Drive å¤åˆ¶ MyNeRFData.zipï¼ˆå¯é€‰ï¼‰"""

import os
from google.colab import drive

drive_zip_path = "/content/drive/MyDrive/MyNeRFData.zip"
local_zip_path = "/content/MyNeRFData.zip"

print("ğŸ“‚ [å¯é€‰] æ­£åœ¨æ£€æŸ¥ Drive ä¸Šæ˜¯å¦å·²æœ‰ MyNeRFData.zip ...")

if not os.path.exists("/content/drive"):
    drive.mount("/content/drive")

if os.path.exists(local_zip_path):
    print(f"âœ… æœ¬åœ°å·²å­˜åœ¨ {local_zip_path}ï¼Œè·³è¿‡ä» Drive å¤åˆ¶ã€‚")
elif os.path.exists(drive_zip_path):
    print(f"ğŸ”„ åœ¨ Drive æ‰¾åˆ°æ•°æ®é›†: {drive_zip_path}")
    print("   -> æ­£åœ¨å¤åˆ¶åˆ°æœ¬åœ° /content/MyNeRFData.zip ...")
    os.system(f"cp '{drive_zip_path}' '{local_zip_path}'")
    print("âœ… å¤åˆ¶å®Œæˆï¼å¯ä»¥ç›´æ¥è¿è¡Œè§£å‹ Cellã€‚")
else:
    print("âš ï¸ Drive ä¸­æœªæ‰¾åˆ° MyNeRFData.zipã€‚")
    print("   -> è‹¥éœ€è¦è¿œç¨‹åŠ è½½ï¼Œè¯·å…ˆæŠŠæ•°æ®é›†ä¸Šä¼ åˆ°: MyDrive/MyNeRFData.zip")
    print("   -> æˆ–è€…æŒ‰åŸæµç¨‹ï¼Œåœ¨å·¦ä¾§æ–‡ä»¶æ æ‰‹åŠ¨ä¸Šä¼ åˆ° /content/MyNeRFData.zip")

"""# Cell 3: æ•°æ®å‡†å¤‡ï¼ˆè§£å‹ Dataset + ç»“æ„ä¿®å¤ + æŒ‚è½½ Driveï¼‰"""

# ==========================================
# æ­¥éª¤ 2 (ä¿®å¤ç‰ˆ): æ™ºèƒ½è§£å‹ä¸å®Œæ•´æ€§æ£€æŸ¥
# è¯´æ˜ï¼šè¯·ä¿è¯ ZIP å†…éƒ¨é¡¶å±‚æ–‡ä»¶å¤¹å‘½åä¸º MyNeRFDataï¼Œ
#       ä¸”æœ€ç»ˆå±•å¼€è·¯å¾„ä¸º data/custom/MyNeRFDataï¼Œå¯¹åº” mobilenerf ä¸­ object_name="MyNeRFData"
# ==========================================
import os
import zipfile

zip_path = '/content/MyNeRFData.zip'
extract_path = '/content/jax3d/jax3d/projects/mobilenerf/data/custom/MyNeRFData'

# 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if not os.path.exists(zip_path):
    print("âŒ é”™è¯¯ï¼šæ ¹æœ¬æ²¡æ‰¾åˆ° /content/MyNeRFData.zipï¼")
    print("ğŸ‘‰ è¯·å°†æ–‡ä»¶æ‹–å…¥å·¦ä¾§æ–‡ä»¶æ ï¼Œå¹¶ç­‰å¾…ä¸Šä¼ å®Œæˆã€‚")
    assert False

# 2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æŸå (å…³é”®æ­¥éª¤)
if not zipfile.is_zipfile(zip_path):
    print("âŒ è‡´å‘½é”™è¯¯ï¼šZIP æ–‡ä»¶å·²æŸåæˆ–æœªä¸Šä¼ å®Œæˆï¼")
    print("ğŸ’¡ åŸå› ï¼šé€šå¸¸æ˜¯å› ä¸ºä½ åœ¨ä¸Šä¼ è¿›åº¦æ¡èµ°å®Œä¹‹å‰å°±ç‚¹å‡»äº†è¿è¡Œã€‚")
    print("ğŸ‘‰ è§£å†³ï¼šè¯·åœ¨å·¦ä¾§åˆ é™¤è¯¥æ–‡ä»¶ï¼Œé‡æ–°ä¸Šä¼ ï¼ŒåŠ¡å¿…ç­‰å¾…ä¸‹æ–¹è¿›åº¦åœˆå®Œå…¨æ¶ˆå¤±ï¼")
    # æ‰“å°æ–‡ä»¶å¤§å°çœ‹çœ‹
    file_size = os.path.getsize(zip_path) / (1024 * 1024)
    print(f"   å½“å‰æ–‡ä»¶å¤§å°ä»…ä¸º: {file_size:.2f} MB (å¦‚æœè¿™ä¸ªæ•°å¾ˆå°ï¼Œè¯´æ˜è‚¯å®šæ²¡ä¼ å®Œ)")
    assert False

print(f"âœ… ZIP æ–‡ä»¶å®Œæ•´ ({os.path.getsize(zip_path)/1024/1024:.2f} MB)ã€‚å‡†å¤‡è§£å‹...")

# 3. åˆ›å»ºç›®å½•
if not os.path.exists(extract_path):
    os.makedirs(extract_path)

# 4. è§£å‹
print(f"ğŸ“‚ æ­£åœ¨è§£å‹åˆ°: {extract_path}")
# ä½¿ç”¨ python è‡ªå¸¦åº“è§£å‹ï¼Œæ¯” shell å‘½ä»¤æ›´ç¨³
try:
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    print("âœ… è§£å‹æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ è§£å‹å¤±è´¥: {e}")
    assert False

# 5. å†æ¬¡æ ¸å®å†…å®¹
# æœ‰æ—¶å€™ zip åŒ…é‡Œè‡ªå¸¦äº†ä¸€å±‚æ–‡ä»¶å¤¹ï¼Œæˆ‘ä»¬éœ€è¦ç¡®è®¤ json åœ¨å“ª
print("ğŸ§ æ ¸å®æ–‡ä»¶ä½ç½®...")
found_json = False
for root, dirs, files in os.walk(extract_path):
    if "transforms_train.json" in files:
        print(f"âœ… æˆåŠŸæ‰¾åˆ°é…ç½®æ–‡ä»¶: {os.path.join(root, 'transforms_train.json')}")
        found_json = True
        break

if not found_json:
    print("âš ï¸ è­¦å‘Šï¼šè§£å‹æˆåŠŸï¼Œä½†æ²¡æ‰¾åˆ° transforms_train.jsonã€‚")
    print("ğŸ‘‡ è¯·æ£€æŸ¥ä¸‹é¢çš„æ–‡ä»¶ç»“æ„ï¼Œçœ‹çœ‹æ˜¯ä¸æ˜¯å¥—äº†ä¸€å±‚æ–‡ä»¶å¤¹ï¼Ÿ")
    for root, dirs, files in os.walk(extract_path):
        level = root.replace(extract_path, '').count(os.sep)
        indent = ' ' * 4 * (level)
        print('{}{}/'.format(indent, os.path.basename(root)))
        subindent = ' ' * 4 * (level + 1)
        for f in files[:5]: # åªæ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶
            print('{}{}'.format(subindent, f))
else:
    print("ğŸ‰ æ•°æ®å‡†å¤‡å®Œç¾å°±ç»ªï¼è¯·ç»§ç»­è¿è¡Œ Step 3ã€‚")

import os
import shutil

nested_dir = '/content/jax3d/jax3d/projects/mobilenerf/data/custom/MyNeRFData/MyNeRFData'
target_dir = '/content/jax3d/jax3d/projects/mobilenerf/data/custom/MyNeRFData'

print("ğŸ”§ æ­£åœ¨æ£€æµ‹æ˜¯å¦å¥—å¨ƒ...")

if os.path.exists(nested_dir):
    print(f"âš ï¸ å‘ç°å¥—å¨ƒæ–‡ä»¶å¤¹ï¼æ­£åœ¨æŠŠæ–‡ä»¶ä» {nested_dir} æ¬å‡ºæ¥...")

    # éå†å¥—å¨ƒæ–‡ä»¶å¤¹é‡Œçš„æ‰€æœ‰æ–‡ä»¶ï¼Œç§»åŠ¨åˆ°å¤–é¢
    for filename in os.listdir(nested_dir):
        src = os.path.join(nested_dir, filename)
        dst = os.path.join(target_dir, filename)

        # å¦‚æœç›®æ ‡å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤ï¼Œé˜²æ­¢æŠ¥é”™
        if os.path.exists(dst):
            if os.path.isdir(dst): shutil.rmtree(dst)
            else: os.remove(dst)

        shutil.move(src, dst)
        print(f"  -> ç§»åŠ¨: {filename}")

    # åˆ æ‰ç©ºçš„å¥—å¨ƒå£³å­
    os.rmdir(nested_dir)
    print("âœ… æ¬å®¶å®Œæˆï¼ç»“æ„å·²ä¿®å¤ã€‚")
else:
    print("â„¹ï¸ æ²¡å‘ç°å¥—å¨ƒæ–‡ä»¶å¤¹ã€‚")
    # æ£€æŸ¥ä¸€ä¸‹æ–‡ä»¶åˆ°åº•åœ¨å“ª
    if os.path.exists(os.path.join(target_dir, "transforms_train.json")):
        print("âœ… ç¡®è®¤ï¼šjson æ–‡ä»¶å·²ç»åœ¨æ­£ç¡®ä½ç½®äº†ã€‚")
    else:
        print("âŒ ä¾ç„¶æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥å·¦ä¾§æ–‡ä»¶æ ç¡®è®¤è·¯å¾„ã€‚")

import os
import time
import threading
import shutil
import re
from google.colab import drive
from IPython import get_ipython

# 1. ç¯å¢ƒå‡†å¤‡
if not os.path.exists('/content/drive'):
    drive.mount('/content/drive')

project_dir = '/content/jax3d/jax3d/projects/mobilenerf'
if os.path.exists(project_dir):
    os.chdir(project_dir)
    os.environ['PYTHONPATH'] += ":/content/jax3d"
else:
    print(f"âŒ æ‰¾ä¸åˆ°é¡¹ç›®ç›®å½•: {project_dir}")

"""# Cell 4: Stage1 å¤‡ä»½ + Stage2 ä»£ç ä¿®å¤å…¥å£"""

# ==============================================================================
# Stage 2 å¼ºåˆ¶ä¿®å¤è„šæœ¬ (æ— è®ºå¦‚ä½•éƒ½è¦æŠŠ 0.033 å¡è¿›å»ï¼)
# ==============================================================================
import os

PROJECT_ROOT = "/content/jax3d/jax3d/projects/mobilenerf"
target_file = os.path.join(PROJECT_ROOT, 'stage2.py')
LOCAL_SAMPLES_DIR = os.path.join(PROJECT_ROOT, "samples_stage2")
# ä½ çš„ Drive è¾“å‡ºè·¯å¾„
DRIVE_OUTPUT_DIR = "/content/drive/MyDrive/Stage1_12Jan/Stage2_Result_256"

print(f"ğŸ”§ æ­£åœ¨æš´åŠ›ä¿®å¤ {target_file} ...")

with open(target_file, 'r') as f:
    lines = f.readlines()

new_lines = []
scale_injected = False

for line in lines:
    # 1. å¼ºåˆ¶ä¿®æ”¹åˆ†è¾¨ç‡ä¸º 256
    if "point_grid_size =" in line and "128" in line:
        line = "    point_grid_size = 256 # [Force 256]\n"
        print("   âœ… åˆ†è¾¨ç‡å·²å¼ºåˆ¶æ”¹ä¸º 256")

    # 2. å¼ºåˆ¶ä¿®æ”¹ Samples è·¯å¾„
    if "os.path.join(base_dir, 'samples')" in line:
        line = line.replace("os.path.join(base_dir, 'samples')", f"'{LOCAL_SAMPLES_DIR}'")
    if "os.path.join(logdir, 'samples')" in line:
        line = line.replace("os.path.join(logdir, 'samples')", f"'{LOCAL_SAMPLES_DIR}'")

    # 3. ğŸ”¥ æ ¸å¿ƒï¼šåœ¨ return ä¹‹å‰å¼ºåˆ¶æ’å…¥ Scale 0.033
    # æˆ‘ä»¬å¯»æ‰¾è¿™ä¸€è¡Œï¼Œä¸€æ—¦æ‰¾åˆ°ï¼Œå°±åœ¨å®ƒå‰é¢æ’é˜Ÿ
    if "return {'images' : images" in line and not scale_injected:
        print("   ğŸ”¥ [é‡è¦] æ­£åœ¨æ³¨å…¥ Scale 0.033 ä»£ç ...")
        # å†™å…¥ç¼©æ”¾é€»è¾‘
        new_lines.append("\n    # [FORCE INJECTED SCALE]\n")
        new_lines.append("    print('âš¡âš¡âš¡ APPLYING SCALE 0.033 âš¡âš¡âš¡')\n")
        new_lines.append("    poses = poses.at[:, :3, 3].set(poses[:, :3, 3] * 0.033)\n")
        new_lines.append(line) # æŠŠåŸæ¥çš„ return å†™å›å»
        scale_injected = True
        continue

    # 4. ä¿®å¤ Stage 1 æƒé‡è¯»å–è·¯å¾„ (é˜²æ­¢è¯»ä¸åˆ°)
    if "pickle.load" in line and "weights_stage1.pkl" in line:
        line = "    vars = pickle.load(open('weights/weights_stage1.pkl', 'rb'))\n"
        print("   âœ… æƒé‡è¯»å–è·¯å¾„å·²ä¿®æ­£")

    new_lines.append(line)

# å†™å›æ–‡ä»¶
with open(target_file, 'w') as f:
    f.writelines(new_lines)

if scale_injected:
    print("\nğŸ‰ ä¿®å¤æˆåŠŸï¼0.033 ç¼©æ”¾ä»£ç å·²å¼ºåˆ¶å†™å…¥ã€‚")
else:
    print("\nâŒ ä¸¥é‡é”™è¯¯ï¼šæ²¡æ‰¾åˆ°æ³¨å…¥ç‚¹ï¼è¯·æ£€æŸ¥ stage2.py å†…å®¹ã€‚")

"""  # Cell 5: ç®€æ˜“ç‰ˆ Stage1 å¯åŠ¨ï¼ˆå¤‡ä»½ + è®­ç»ƒï¼‰"""

# ==============================================================================
# ğŸ›¡ï¸ Stage1 Step 1: å¼ºç›—å¤‡ä»½è„šæœ¬
# ==============================================================================
local_checkpoints = "checkpoints"
local_weights = "weights"
local_samples = "samples"

drive_root = "/content/drive/MyDrive/Stage1_12Jan"
drive_checkpoints = os.path.join(drive_root, "checkpoints")
drive_weights = os.path.join(drive_root, "weights")
drive_samples = os.path.join(drive_root, "samples")

def background_backup():
    print("ğŸ›¡ï¸ åå°å¤‡ä»½æœåŠ¡å·²å¯åŠ¨...")
    while True:
        try:
            if os.path.exists(local_checkpoints):
                if not os.path.exists(drive_checkpoints): os.makedirs(drive_checkpoints)
                os.system(f"cp -ru '{local_checkpoints}/.' '{drive_checkpoints}/'")
            if os.path.exists(local_weights):
                if not os.path.exists(drive_weights): os.makedirs(drive_weights)
                os.system(f"cp -ru '{local_weights}/.' '{drive_weights}/'")
            if os.path.exists(local_samples):
                if not os.path.exists(drive_samples): os.makedirs(drive_samples)
                os.system(f"cp -ru '{local_samples}/.' '{drive_samples}/'")
        except:
            pass
        time.sleep(30)

t = threading.Thread(target=background_backup)
t.daemon = True
t.start()

# ==============================================================================
# ğŸš€ Stage1 Step 2: å¯åŠ¨è®­ç»ƒ
# ==============================================================================
print("ğŸš€ å¯åŠ¨è®­ç»ƒ...")

cmd = """
source activate mobilenerf && export MPLBACKEND=Agg && python stage1.py \
  --gin_configs=configs/360.gin \
  --gin_bindings="Config.dataset_loader='blender'" \
  --gin_bindings="Config.batch_size=4096" \
  --gin_bindings="Config.data_dir='/content/jax3d/jax3d/projects/mobilenerf/data/custom/MyNeRFData'" \
  --gin_bindings="Config.checkpoint_dir='/content/jax3d/jax3d/projects/mobilenerf/checkpoints'" \
  --gin_bindings="Config.render_every=1000" \
  --gin_bindings="Config.save_every=2000" \
  --logtostderr
"""

get_ipython().system(cmd)

"""# Cell 6: Stage2 é€‚é… .pkl å­˜æ¡£ + Scale 0.033"""

# ==============================================================================
# ğŸ›¡ï¸ Stage 2 å¤åˆ»ä¿®æ­£ç‰ˆ (ä¿®å¤è·¯å¾„ + Scale 0.033 + Res 256)
# ==============================================================================
import os
import re
import pickle
import shutil
import glob
from google.colab import drive
from IPython import get_ipython

# --- 1. è·¯å¾„ä¸å‚æ•°é…ç½® ---
# Drive æºå¤´ (Stage 1 æƒé‡)
DRIVE_SOURCE_PKL_DIR = "/content/drive/MyDrive/Stage1_12Jan/weights"
# Drive è¾“å‡º (Stage 2 ç»“æœ) - ç›´æ¥å­˜è¿™é‡Œé˜²æ–­è¿
DRIVE_OUTPUT_DIR = "/content/drive/MyDrive/Stage1_12Jan/Stage2_Result_256"

# æœ¬åœ°è·¯å¾„
PROJECT_ROOT = "/content/jax3d/jax3d/projects/mobilenerf"
LOCAL_WEIGHTS_DIR = os.path.join(PROJECT_ROOT, "weights")
LOCAL_SAMPLES_DIR = os.path.join(PROJECT_ROOT, "samples_stage2")

# å…³é”®å‚æ•°
TARGET_SCALE = 0.033
TARGET_GRID = 256

# ==============================================================================
# Stage2 [Step 1] ç¯å¢ƒå‡†å¤‡
# ==============================================================================
print("ğŸšš [1/4] ç¯å¢ƒå‡†å¤‡ä¸­...")

if not os.path.exists('/content/drive'): drive.mount('/content/drive')
if not os.path.exists(LOCAL_WEIGHTS_DIR): os.makedirs(LOCAL_WEIGHTS_DIR)
if not os.path.exists(LOCAL_SAMPLES_DIR): os.makedirs(LOCAL_SAMPLES_DIR)
if not os.path.exists(DRIVE_OUTPUT_DIR): os.makedirs(DRIVE_OUTPUT_DIR)

# æ¬è¿æƒé‡ (ç¡®ä¿ weights/weights_stage1.pkl å­˜åœ¨)
print(f"    ğŸ“¥ æ­£åœ¨æŸ¥æ‰¾ Stage 1 æƒé‡...")
pkl_files = glob.glob(os.path.join(DRIVE_SOURCE_PKL_DIR, "*.pkl"))
if not pkl_files:
    pkl_files = glob.glob(os.path.join(os.path.dirname(DRIVE_SOURCE_PKL_DIR), "*.pkl"))

if pkl_files:
    pkl_files.sort(key=os.path.getmtime)
    target_pkl = pkl_files[-1]
    shutil.copy2(target_pkl, os.path.join(LOCAL_WEIGHTS_DIR, "weights_stage1.pkl"))
    print(f"      -> å·²å°±ä½: {os.path.basename(target_pkl)}")
else:
    print("âŒ é”™è¯¯ï¼šDrive é‡Œæ²¡æ‰¾åˆ° .pkl æ–‡ä»¶ï¼")
    assert False

# ==============================================================================
# Stage2 [Step 2] ä»£ç æ‰‹æœ¯ï¼ˆè·¯å¾„ä¸é‡‡æ ·é…ç½®ï¼‰
# ==============================================================================
target_file = os.path.join(PROJECT_ROOT, 'stage2.py')
print(f"ğŸ’‰ [2/4] ä¿®æ”¹ä»£ç ...")

with open(target_file, 'r') as f:
    content = f.read()

# 1. åŸºç¡€ä¿®å¤
content = re.sub(r'object_name = "chair"', 'object_name = "MyNeRFData"', content)
content = re.sub(r'scene_dir = "datasets/nerf_synthetic/.*?\+object_name', 'scene_dir = "data/custom/"+object_name', content)
content = content.replace("import matplotlib.pyplot as plt", "import matplotlib; matplotlib.use('Agg'); import matplotlib.pyplot as plt")

# 3. ä¿®æ­£ Samples è¾“å‡ºè·¯å¾„
content = content.replace("os.path.join(base_dir, 'samples')", f"'{LOCAL_SAMPLES_DIR}'")
content = content.replace("os.path.join(logdir, 'samples')", f"'{LOCAL_SAMPLES_DIR}'")

# 4. [å…³é”®ä¿®æ”¹] å‡çº§åˆ†è¾¨ç‡åˆ° 256
if "point_grid_size = 128" in content:
    content = content.replace("point_grid_size = 128", f"point_grid_size = {TARGET_GRID} # [A100 Force]")
    print(f"    âœ… åˆ†è¾¨ç‡å·²ä¿®æ”¹ä¸º {TARGET_GRID}")

# 5. [å…³é”®ä¿®æ”¹] æ³¨å…¥ Scale 0.033
original_return = "return {'images' : images, 'c2w' : poses, 'hwf' : hwf}"
if "poses[:, :3, 3] * " + str(TARGET_SCALE) not in content:
    injection_code = f"""
    # [Auto-Scale Injection]
    print("âš¡ Applying Scale {TARGET_SCALE}...")
    poses = poses.at[:, :3, 3].set(poses[:, :3, 3] * {TARGET_SCALE})
    {original_return}
    """
    content = content.replace(original_return, injection_code)
    print(f"    âœ… Scale {TARGET_SCALE} æ³¨å…¥ä»£ç å·²æ’å…¥")

# 6. ä¿®å¤ Stage 1 æƒé‡è¯»å– (ç¡®ä¿è¯» weights/weights_stage1.pkl)
# åŸä»£ç å¯èƒ½æ˜¯ pickle.load(open(weights_dir+"/"+"weights_stage1.pkl", "rb"))
# æˆ‘ä»¬ç›´æ¥ç¡¬æ”¹
if 'weights_stage1.pkl' in content:
    # è¿™é‡Œçš„æ­£åˆ™ç¨å¾®å®½æ³›ä¸€ç‚¹ï¼ŒåŒ¹é… open(...) é‡Œçš„å†…å®¹
    content = re.sub(r'open\(.*?"weights_stage1\.pkl".*?,', 'open("weights/weights_stage1.pkl",', content)

with open(target_file, 'w') as f:
    f.write(content)

# ==============================================================================
# Stage2 [Step 3] å¯åŠ¨ Stage 2
# ==============================================================================
print(f"\nğŸš€ [3/4] å¯åŠ¨ Stage 2 ...")
print(f"    ğŸ’¾ å­˜æ¡£å°†ç›´æ¥å†™å…¥: {DRIVE_OUTPUT_DIR}")

os.chdir(PROJECT_ROOT)

# å¯åŠ¨å‘½ä»¤
cmd = f"""
source activate mobilenerf && export MPLBACKEND=Agg && python stage2.py \
  --gin_configs=configs/360.gin \
  --gin_bindings="Config.dataset_loader='blender'" \
  --gin_bindings="Config.batch_size=2048" \
  --gin_bindings="Config.data_dir='data/custom/MyNeRFData'" \
  --gin_bindings="Config.checkpoint_dir='{DRIVE_OUTPUT_DIR}'" \
  --logtostderr
"""

get_ipython().system(cmd)

# ==============================================================================
# Stage2 [Step 4] é¢å¤–å¤‡ä»½ Samples
# ==============================================================================
print("\nğŸ“¦ [4/4] å¤‡ä»½ Samples å›¾ç‰‡...")
if os.path.exists(LOCAL_SAMPLES_DIR):
    drive_sample_dest = DRIVE_OUTPUT_DIR + "_samples"
    if not os.path.exists(drive_sample_dest): os.makedirs(drive_sample_dest)
    os.system(f"cp -r '{LOCAL_SAMPLES_DIR}/.' '{drive_sample_dest}/'")

"""# Cell 7: Stage3 æå– Mesh ä¸çº¹ç†ï¼ˆé€‚é… Drive è¯»å– + ç‹¬ç«‹è¾“å‡ºï¼‰"""

# ==============================================================================
# ğŸ›ï¸ Stage 3 æœ€ç»ˆç‰ˆï¼ˆæ¥åŠ›æƒé‡å¯¼å‡º Mesh + çº¹ç†ï¼‰
# ==============================================================================
import os
import re
import shutil
from google.colab import drive
from IPython import get_ipython

# --- 1. è·¯å¾„é…ç½® ---
PROJECT_ROOT = "/content/jax3d/jax3d/projects/mobilenerf"

# å…³é”®ï¼šè¯»å–åˆšæ‰ Stage 2 åˆšç”Ÿæˆçš„æ–°æƒé‡ (æœ¬åœ°)
LOCAL_S2_WEIGHTS_READ = os.path.join(PROJECT_ROOT, "weights")

# è¾“å‡ºè·¯å¾„
LOCAL_S3_OBJ_SAVE = os.path.join(PROJECT_ROOT, "obj_stage3_256")
LOCAL_S3_SAMPLES_SAVE = os.path.join(PROJECT_ROOT, "samples_stage3_256")

# Drive å¤‡ä»½è·¯å¾„
DRIVE_FINAL_EXPORT = "/content/drive/MyDrive/Stage1_12Jan/Final_Sponza_256"

# ================= Step 1: ç¯å¢ƒå‡†å¤‡ & æƒé‡æ£€æŸ¥ =================
print("ğŸšš [1/4] æ­£åœ¨æ£€æŸ¥æƒé‡...")

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
if not os.path.exists(LOCAL_S3_OBJ_SAVE): os.makedirs(LOCAL_S3_OBJ_SAVE)
if not os.path.exists(LOCAL_S3_SAMPLES_SAVE): os.makedirs(LOCAL_S3_SAMPLES_SAVE)

# æ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰åˆšæ‰ Stage 2 è·‘å‡ºæ¥çš„æƒé‡
if not os.path.exists(LOCAL_S2_WEIGHTS_READ):
    print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° Stage 2 çš„è¾“å‡ºç›®å½•: {LOCAL_S2_WEIGHTS_READ}")
    print("   è¯·ç¡®ä¿åˆšæ‰çš„ Stage 2 å·²ç»æˆåŠŸè·‘å®Œï¼")
    assert False

# æ‰¾æœ€æ–°çš„æƒé‡æ–‡ä»¶
pkl_files = [f for f in os.listdir(LOCAL_S2_WEIGHTS_READ) if f.endswith(".pkl")]
if not pkl_files:
    print(f"âŒ é”™è¯¯ï¼šåœ¨ {LOCAL_S2_WEIGHTS_READ} é‡Œæ²¡æ‰¾åˆ° .pkl æ–‡ä»¶ï¼")
    assert False

# æ’åºæ‰¾åˆ°æœ€æ–°çš„ (é€šå¸¸æ˜¯ checkpoint_20000 è¿™ç§)
pkl_files.sort(key=lambda x: int(re.search(r'\d+', x).group()) if re.search(r'\d+', x) else 0)
target_pkl = pkl_files[-1]
print(f"   âœ… é”å®š Stage 2 æƒé‡: {target_pkl}")

# âš ï¸ å…³é”®åŠ¨ä½œï¼šæŠŠè¿™ä¸ªæ–‡ä»¶å¤åˆ¶ä¸€ä»½å¹¶åœ¨åŸåœ°æ”¹åä¸º 'weights_stage2_1.pkl'
# å› ä¸º Stage 3 ä»£ç é‡Œé€šå¸¸å†™æ­»è¯»è¿™ä¸ªåå­—ï¼Œæˆ–è€…è¯» list çš„æœ€åä¸€ä¸ª
# ä¸ºäº†ç¨³å¦¥ï¼Œæˆ‘ä»¬æ‰‹åŠ¨å¸®å®ƒå‡†å¤‡å¥½
dest_pkl = os.path.join(LOCAL_S2_WEIGHTS_READ, "weights_stage2_1.pkl")
shutil.copy2(os.path.join(LOCAL_S2_WEIGHTS_READ, target_pkl), dest_pkl)
print(f"   ğŸ“¦ å·²å‡†å¤‡å¥½æ ‡å‡†å‘½åæƒé‡: weights_stage2_1.pkl")


# ================= Step 2: ä»£ç ç²¾å‡†æ‰‹æœ¯ =================
print("\nğŸ’‰ [2/4] ä¿®æ”¹ Stage 3 ä»£ç  (åˆ†è¾¨ç‡256 + ç›’å­0.7)...")

target_file = os.path.join(PROJECT_ROOT, 'stage3.py')
with open(target_file, 'r') as f:
    content = f.read()

# A. è·¯å¾„ä¿®å¤
content = content.replace('object_name = "chair"', 'object_name = "MyNeRFData"')
content = content.replace('scene_dir = "datasets/nerf_synthetic/"+object_name', 'scene_dir = "data/custom/"+object_name')
# æŒ‡å‘æˆ‘ä»¬åˆšå‡†å¤‡å¥½çš„æœ¬åœ°ç›®å½•
content = content.replace('weights_dir = "weights"', f'weights_dir = "{LOCAL_S2_WEIGHTS_READ}"')
content = content.replace('obj_save_dir = "obj"', f'obj_save_dir = "{LOCAL_S3_OBJ_SAVE}"')
content = content.replace('samples_dir = "samples"', f'samples_dir = "{LOCAL_S3_SAMPLES_SAVE}"')

# B. ğŸ”¥ å…³é”®åŒæ­¥ï¼šåˆ†è¾¨ç‡å¿…é¡»æ˜¯ 256 (åŒ¹é… Stage 2)
if "point_grid_size = 128" in content:
    content = content.replace("point_grid_size = 128", "point_grid_size = 256 # [MATCH STAGE 2]")
    print("   âœ… åˆ†è¾¨ç‡å·²åŒæ­¥ä¸º 256 (åŒ¹é…æƒé‡)")
elif "point_grid_size = 256" in content:
    print("   âœ… åˆ†è¾¨ç‡ä¿æŒ 256")

# C. ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šç›’å­å¤§å° Scale 0.7 (é€‚é… 1.22m Sponza)
# 1.4m çš„ç›’å­è£… 1.22m çš„ç‰©ä½“ï¼Œåˆ©ç”¨ç‡æé«˜
if "scene_grid_scale = 1.2" in content:
    content = content.replace("scene_grid_scale = 1.2", "scene_grid_scale = 0.7 # [Fit Sponza]")
    print("   âœ… æ•è·æ¡†ä¼˜åŒ–ä¸º 0.7 (ç´§å‡‘é«˜ç²¾)")
elif "scene_grid_scale = 0.2" in content:
    content = content.replace("scene_grid_scale = 0.2", "scene_grid_scale = 0.7 # [Fit Sponza]")
    print("   âœ… æ•è·æ¡†ä¿®æ­£ä¸º 0.7")

# D. JAX Scale æ³¨å…¥ (ä¿æŒ 0.033)
if "poses = np.stack(cams, axis=0)" in content:
    content = content.replace("poses[:, :3, 3] *= 0.033", "")
    if ".at[" not in content:
        content = content.replace(
            "poses = np.stack(cams, axis=0)",
            "poses = np.stack(cams, axis=0)\n    poses = poses.at[:, :3, 3].set(poses[:, :3, 3] * 0.033) # [JAX Scale]"
        )

# E. ç§»é™¤ Testing (åŠ é€Ÿ)
if 'print("Testing")' in content:
    content = content.replace('print("Testing")', '# print("Testing")')
    content = content.replace('for i in tqdm(range(len(data[\'test\'][\'images\']))):', 'for i in []:\n  pass')
    content = content.replace('for p in tqdm(render_poses):', 'for p in []:\n  pass')

with open(target_file, 'w') as f:
    f.write(content)

# ================= Step 3: å¯åŠ¨ =================
print("\nğŸš€ [3/4] å¯åŠ¨ Stage 3 (High Res Export)...")
os.chdir(PROJECT_ROOT)
cmd = "source activate mobilenerf && export MPLBACKEND=Agg && python stage3.py"

try:
    get_ipython().system(cmd)
    print("\nğŸ‰ Stage 3 æå–ç»“æŸï¼")
except Exception as e:
    print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")

# ================= Step 4: å¤‡ä»½ =================
print("\nğŸ“¦ [4/4] å¤‡ä»½æœ€ç»ˆç»“æœåˆ° Drive...")
if not os.path.exists('/content/drive'): drive.mount('/content/drive')
if not os.path.exists(DRIVE_FINAL_EXPORT): os.makedirs(DRIVE_FINAL_EXPORT)

if os.path.exists(LOCAL_S3_OBJ_SAVE):
    print(f"   -> æ­£åœ¨å¤‡ä»½ OBJ/GLB åˆ°: {DRIVE_FINAL_EXPORT}")
    os.system(f"cp -r '{LOCAL_S3_OBJ_SAVE}/.' '{DRIVE_FINAL_EXPORT}/'")

    # å¤‡ä»½ Phone ç‰ˆ
    phone_src = LOCAL_S3_OBJ_SAVE + "_phone"
    if os.path.exists(phone_src):
        phone_dst = os.path.join(DRIVE_FINAL_EXPORT, "obj_phone")
        if not os.path.exists(phone_dst): os.makedirs(phone_dst)
        os.system(f"cp -r '{phone_src}/.' '{phone_dst}/'")

print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼é«˜ç²¾åº¦ Sponza å·²ä¿å­˜è‡³: {DRIVE_FINAL_EXPORT}")

"""# Cell 7: Hybrid ä»£ç æ‹‰å–ï¼ˆç‹¬ç«‹äº JAX ç¯å¢ƒï¼‰
"""

"""# Cell 7: Hybrid ä»£ç æ‹‰å–ï¼ˆç‹¬ç«‹äº JAX ç¯å¢ƒï¼‰"""
# ç”¨é€”ï¼š
# - ä»…ä¸º Hybrid 01/02ã€è¯Šæ–­è„šæœ¬ã€xatlas å·¥å…·æä¾›ä»£ç ç›®å½•
# ä½¿ç”¨åœºæ™¯ï¼š
# - å¦‚æœä½ åªè·‘ Hybrid Pipelineï¼Œå¯ä»¥è·³è¿‡å‰é¢çš„ JAX Stage1/2 ç›¸å…³ Cellï¼Œä»æœ¬ Cell å¼€å§‹

import os
import shutil

MY_REPO_HYBRID = "https://github.com/Davecodingking/jax3d_David.git"
TARGET_DIR_HYBRID = "/content/jax3d"

print("ğŸš€ [Hybrid Repo] æ­£åœ¨å‡†å¤‡ jax3d_David ä»£ç ï¼ˆä¾› 01/02 ä½¿ç”¨ï¼‰...")

if os.path.exists(TARGET_DIR_HYBRID) or os.path.exists("/content/jax3d_David"):
    print("â„¹ï¸ æ£€æµ‹åˆ°ç°æœ‰ä»£ç ç›®å½•ï¼Œå°†ç›´æ¥å¤ç”¨å½“å‰ç‰ˆæœ¬ã€‚")
else:
    print(f"ğŸ“¥ æ­£åœ¨å…‹éš†ä»“åº“: {MY_REPO_HYBRID}")
    !git clone {MY_REPO_HYBRID}
    if os.path.exists("/content/jax3d_David"):
        shutil.move("/content/jax3d_David", TARGET_DIR_HYBRID)
        print("âœ… ä»£ç å·²å°±ä½ (jax3d_David -> jax3d)")
    else:
        print("âŒ å…‹éš†å¤±è´¥ï¼Œè¯·æ£€æŸ¥ GitHub ä»“åº“åœ°å€æˆ–ç½‘ç»œè¿æ¥ã€‚")

"""# Cell 8: ç¯å¢ƒé…ç½® ï¼ˆPyTorch 2.1 + NumPy 1.26 + PyTorch3D Wheelï¼‰
"""

"""# Cell 8-UV: 01_preprocess_raster ä¸“ç”¨ç¯å¢ƒï¼ˆWheelåŠ é€Ÿ + NumPyä¿®å¤ç‰ˆï¼‰"""
# ç”¨é€”ï¼š
# - ç»™ 01_preprocess_raster.pyã€å„ç±» PyTorch3D è¯Šæ–­è„šæœ¬ã€xatlas å¯¹æ¯”è„šæœ¬æä¾›ç‹¬ç«‹ç¯å¢ƒ
# ä½•æ—¶éœ€è¦è¿è¡Œï¼š
# - æ¯æ¬¡ Colab Runtime å…¨æ–°å¯åŠ¨ / æ–­çº¿é‡è¿åï¼Œç¬¬ä¸€æ¬¡è·‘ Hybrid / è¯Šæ–­ / xatlas å‰è¿è¡Œ 1 æ¬¡
# - å·²åœ¨å½“å‰ä¼šè¯æˆåŠŸåˆ›å»ºè¿‡ hybrid_uv_wheel æ—¶ï¼Œå¯ä»¥è·³è¿‡æœ¬ Cell

import os

# 1. åˆ›å»ºç¯å¢ƒ (Python 3.10)
print("ğŸš€ [Hybrid UV Env] æ­£åœ¨åˆ›å»º Python 3.10 ç¯å¢ƒ...")
!conda create -n hybrid_uv_wheel python=3.10 -y

# 2. å®‰è£… PyTorch 2.1.0 + CUDA 11.8 + â˜…NumPy 1.26.4â˜…
# å…³é”®ä¿®å¤ï¼šæ˜¾å¼åŠ ä¸Š numpy=1.26.4ï¼Œé˜²æ­¢å®‰è£… NumPy 2.x
print("â³ æ­£åœ¨å®‰è£… PyTorch 2.1.0 å’Œ NumPy 1.26.4...")
!source activate hybrid_uv_wheel && conda install -y \
    pytorch=2.1.0 torchvision=0.16.0 torchaudio=2.1.0 \
    pytorch-cuda=11.8 \
    numpy=1.26.4 \
    -c pytorch -c nvidia

# 3. å®‰è£…ä¾èµ– (fvcore, iopath)
# ä½¿ç”¨ pip å®‰è£…æ—¶ä¹Ÿé™åˆ¶ numpy ç‰ˆæœ¬ï¼Œé˜²æ­¢è¢«å‡çº§
print("â³ æ­£åœ¨å®‰è£…åŸºç¡€ä¾èµ–...")
!source activate hybrid_uv_wheel && pip install "numpy<2" fvcore iopath matplotlib pillow


# 4. å®‰è£… PyTorch3D å®˜æ–¹ Wheel åŒ… (GPU åŠ é€Ÿæ ¸å¿ƒ)
print("â³ æ­£åœ¨å®‰è£… PyTorch3D å®˜æ–¹åŠ é€ŸåŒ…...")
!source activate hybrid_uv_wheel && pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py310_cu118_pyt210/download.html

print("\nâœ… ç¯å¢ƒé…ç½®å®Œæˆï¼NumPyç‰ˆæœ¬å·²é”å®šï¼ŒCUDAåŠ é€Ÿå·²å°±ç»ªã€‚")

"""# Cell 8: Hybrid Workflow ç¯å¢ƒé…ç½®ï¼ˆåŸºäº Colab é»˜è®¤ç¯å¢ƒï¼‰"""
# ç”¨é€”ï¼š
# - åœ¨ Colab é»˜è®¤ Python ç¯å¢ƒä¸­å®‰è£… Torch + PyTorch3Dï¼Œä¾› 02_train_hybrid.py ä½¿ç”¨
# ä½•æ—¶éœ€è¦è¿è¡Œï¼š
# - æ¯æ¬¡ Colab Runtime å…¨æ–°å¯åŠ¨ / æ–­çº¿é‡è¿åï¼Œç¬¬ä¸€æ¬¡è·‘ Hybrid è®­ç»ƒï¼ˆCell 10/11ï¼‰å‰è¿è¡Œ 1 æ¬¡
# - å¦‚æœå½“å‰ä¼šè¯å·²ç»å®‰è£…è¿‡ torch / pytorch3dï¼Œæœ¬ Cell å¯è·³è¿‡

print("\nğŸš€ [Hybrid Env] é…ç½® Torch + PyTorch3D ç¯å¢ƒï¼ˆä½¿ç”¨ Colab é»˜è®¤ Pythonï¼‰...")
!pip install --upgrade pip
!pip install "numpy<2"
!pip install torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0+cu118 -f https://download.pytorch.org/whl/torch_stable.html

# !pip install --upgrade pip
# !pip install "numpy<2" --force-reinstall
# !pip install torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0+cu118 -f https://download.pytorch.org/whl/torch_stable.html

"""# Cell 9:Hybrid Pipeline Step 1 - é¢„è®¡ç®— UV (PyTorch3D)"""

"""# Cell 9: Hybrid Pipeline Step 1 - é¢„è®¡ç®— UV (è¿è¡Œ)"""
# ä½œç”¨ï¼š
# - åœ¨ hybrid_uv_wheel ç¯å¢ƒä¸­è°ƒç”¨ 01_preprocess_raster.pyï¼Œç”Ÿæˆ uv_lookup.npz
# ä½•æ—¶éœ€è¦è¿è¡Œï¼š
# - ç¬¬ä¸€æ¬¡ä¸ºå½“å‰ MyNeRFData åœºæ™¯ç”Ÿæˆ UV æ˜ å°„æ—¶å¿…é¡»è¿è¡Œ
# - è‹¥ä¿®æ”¹äº† OBJ / transforms_*ï¼Œéœ€è¦é‡æ–°è¿è¡Œä»¥æ›´æ–° uv_lookup.npz
# - è‹¥ Colab é‡å¯ä½† Drive ä¸­å·²æœ‰ uv_lookup.npzï¼Œå¯ä¾èµ– Cell 10/11 è‡ªåŠ¨ä» Drive æ¢å¤ï¼Œæœ¬ Cell å¯é€‰

import os
from IPython import get_ipython
from google.colab import drive
import numpy as np

PROJECT_ROOT_HYBRID = "/content/jax3d/jax3d/projects/mobilenerf"
DRIVE_HYBRID_ROOT = "/content/drive/MyDrive/Hybrid_Pipeline"
HYBRID_DATA_ROOT = "data/custom/MyNeRFData"
HYBRID_OBJ_NAME = "sponza_gt_unwarpped.obj"
HYBRID_TRANSFORMS = "transforms_train.json"
HYBRID_UV_OUTPUT = "uv_lookup.npz"

print("\nğŸš€ [Hybrid 1/2] é¢„è®¡ç®— UV æ˜ å°„ (GPU åŠ é€Ÿæ¨¡å¼)...")

if not os.path.exists("/content/drive"):
    drive.mount("/content/drive")

if not os.path.exists(DRIVE_HYBRID_ROOT):
    os.makedirs(DRIVE_HYBRID_ROOT)

if os.path.exists(PROJECT_ROOT_HYBRID):
    os.chdir(PROJECT_ROOT_HYBRID)

    # æ³¨æ„ï¼šè¿™é‡Œæ¿€æ´»çš„æ˜¯ hybrid_uv_wheel ç¯å¢ƒ
    cmd = f"""
    source activate hybrid_uv_wheel && \
    python 01_preprocess_raster.py \
      --data_root='{HYBRID_DATA_ROOT}' \
      --obj_name='{HYBRID_OBJ_NAME}' \
      --transforms='{HYBRID_TRANSFORMS}' \
      --output='{HYBRID_UV_OUTPUT}' \
      --downscale=1 \
      --device='cuda'
    """

    get_ipython().system(f"bash -c '{cmd}'")

    uv_path = os.path.join(PROJECT_ROOT_HYBRID, HYBRID_DATA_ROOT, HYBRID_UV_OUTPUT)
    if os.path.exists(uv_path):
        data = np.load(uv_path, allow_pickle=True)
        print(f"âœ… UV æ˜ å°„ç”Ÿæˆå®Œæˆï¼Œå½¢çŠ¶: {data['uv'].shape}")
        # å¤åˆ¶åˆ° Google Drive å¤‡ä»½
        os.system(f"cp '{uv_path}' '{DRIVE_HYBRID_ROOT}/'")
        print(f"âœ… å¤‡ä»½å®Œæˆï¼ç°åœ¨å»è¿è¡Œè®­ç»ƒå§ã€‚")
    else:
        print("âš ï¸ æœªæ‰¾åˆ° uv_lookup.npzï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹æŠ¥é”™")
else:
    print(f"âŒ æ‰¾ä¸åˆ°é¡¹ç›®ç›®å½•: {PROJECT_ROOT_HYBRID}")

"""# Cell 9.2: Overlay æ£€æŸ¥ - Forensic (Top-Down + Overlay"""

"""# Cell 9.2: Overlay æ£€æŸ¥ - Forensic (Top-Down + Overlay)"""
# ç”¨é€”ï¼š
# - ä½¿ç”¨ PyTorch3D åœ¨ hybrid_uv_wheel ç¯å¢ƒä¸­åš Top-Down + Overlay è°ƒè¯•ï¼Œæ£€æŸ¥æ¨¡å‹æœå‘ä¸ç›¸æœºå¯¹é½
# è¯´æ˜ï¼š
# - å®Œå…¨å¯é€‰ï¼Œä»…åœ¨ä½ éœ€è¦æ·±å…¥æ’æŸ¥å‡ ä½• / ç›¸æœºé—®é¢˜æ—¶è¿è¡Œ

code_content = r'''
import os
import json
import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from pytorch3d.io import load_obj
from pytorch3d.structures import Meshes
from pytorch3d.renderer import (
    PerspectiveCameras, RasterizationSettings, MeshRasterizer,
    MeshRenderer, HardPhongShader, PointLights, TexturesVertex,
    look_at_view_transform
)

# ================= é…ç½® =================
DATA_ROOT = "data/custom/MyNeRFData"
OBJ_NAME = "sponza_gt.obj"
TRANSFORMS = "transforms_train.json"
DEVICE = "cuda"
VIEW_INDEX = 0
# =======================================

def forensic_investigation_fixed():
    print("ğŸ•µï¸â€â™‚ï¸ å¯åŠ¨æœ€ç»ˆæ’æŸ¥ (è‡ªåŠ¨åˆ†è¾¨ç‡é€‚é…ç‰ˆ)...")

    # 1. å‡†å¤‡æ•°æ®
    json_path = os.path.join(DATA_ROOT, TRANSFORMS)
    if not os.path.exists(json_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° {json_path}")
        return

    with open(json_path, "r") as f:
        meta = json.load(f)
    frame = meta["frames"][VIEW_INDEX]

    # å›¾ç‰‡
    img_path = os.path.join(DATA_ROOT, frame["file_path"] + ".png")
    if not os.path.exists(img_path): img_path = img_path.replace(".png", ".jpg")
    gt_image = np.array(Image.open(img_path).convert("RGB")) / 255.0
    H, W, _ = gt_image.shape
    print(f"ğŸ“· æ£€æµ‹åˆ°å›¾åƒå°ºå¯¸: {H}x{W}")

    # æ¨¡å‹
    obj_path = os.path.join(DATA_ROOT, OBJ_NAME)
    verts, faces, _ = load_obj(obj_path)
    verts = verts.to(DEVICE).float()
    faces_idx = faces.verts_idx.to(DEVICE).long()

    # ç»™æ¨¡å‹ä¸Šç™½è‰²
    verts_rgb = torch.ones_like(verts)[None]
    textures = TexturesVertex(verts_features=verts_rgb)
    mesh = Meshes(verts=[verts], faces=[faces_idx], textures=textures)

    plt.figure(figsize=(16, 8))

    # â˜…â˜…â˜… å…³é”®ä¿®å¤ï¼šä½¿ç”¨ (H, W) è€Œä¸æ˜¯å†™æ­» 512 â˜…â˜…â˜…
    raster_settings = RasterizationSettings(
        image_size=(H, W),  # <--- è¿™é‡Œæ”¹äº†ï¼Œç»å¯¹ä¸ä¼šå†æŠ¥é”™
        blur_radius=0.0,
        faces_per_pixel=1,
        cull_backfaces=True
    )

    # -------------------------------------------------------------
    # è§†è§’ A: ä¸Šå¸è§†è§’ (Top-Down View) - æŸ¥æ¨¡å‹æ–¹å‘
    # -------------------------------------------------------------
    # æ”¾åœ¨ Y=50 çš„é«˜ç©ºï¼Œå¾€ä¸‹çœ‹ (0,0,0)ã€‚
    R_top, T_top = look_at_view_transform(
        dist=50.0,
        elev=90.0,
        azim=0.0,
        device=DEVICE
    )

    cameras_top = PerspectiveCameras(device=DEVICE, R=R_top, T=T_top)
    lights_top = PointLights(device=DEVICE, location=[[0.0, 50.0, 0.0]])

    renderer_top = MeshRenderer(
        rasterizer=MeshRasterizer(cameras=cameras_top, raster_settings=raster_settings),
        shader=HardPhongShader(device=DEVICE, cameras=cameras_top, lights=lights_top)
    )

    img_top = renderer_top(mesh)[0, ..., :3].cpu().numpy()

    plt.subplot(1, 2, 1)
    plt.title(f"A: Top-Down View\n(Is the corridor Horizontal-X or Vertical-Z?)")
    plt.imshow(img_top)
    plt.axis("off")

    # -------------------------------------------------------------
    # è§†è§’ B: è¯´æ˜ä¹¦éªŒè¯ (Standard Unity->PyTorch3D) - æŸ¥å¯¹é½
    # -------------------------------------------------------------
    # å…¬å¼ï¼šFlip X

    raw_c2w = np.array(frame["transform_matrix"], dtype=np.float32)
    c2w = raw_c2w.copy()

    # 1. ç¿»è½¬ X è½´
    #c2w[:3, 0] *= -1
    # 2. ç¿»è½¬ X ä½ç½®
    #c2w[0, 3] *= -1

    c2w_torch = torch.from_numpy(c2w).to(DEVICE).unsqueeze(0)
    w2c = torch.inverse(c2w_torch)

    # è®¡ç®—é€è§†
    camera_angle_x = float(meta["camera_angle_x"])
    focal = 0.5 * W / np.tan(0.5 * camera_angle_x)

    cameras_std = PerspectiveCameras(
        device=DEVICE, R=w2c[:, :3, :3], T=w2c[:, :3, 3],
        focal_length=((focal, focal),),
        principal_point=((W/2, H/2),),
        image_size=((H, W),),
        in_ndc=False
    )

    lights_std = PointLights(device=DEVICE, location=[[0.0, 0.0, 0.0]])
    renderer_std = MeshRenderer(
        rasterizer=MeshRasterizer(cameras=cameras_std, raster_settings=raster_settings),
        shader=HardPhongShader(device=DEVICE, cameras=cameras_std, lights=lights_std)
    )

    img_std = renderer_std(mesh)[0, ..., :3].cpu().numpy()

    # å åŠ éªŒè¯
    overlay = gt_image.copy()
    mask = img_std.sum(axis=-1) > 0.1
    # è¿™é‡Œçš„ img_std ç°åœ¨ä¹Ÿæ˜¯ (H, W)ï¼Œå’Œ overlay ä¸€æ ·å¤§ï¼Œä¸ä¼šæŠ¥é”™
    overlay[mask] = overlay[mask] * 0.5 + img_std[mask] * 0.5

    plt.subplot(1, 2, 2)
    plt.title("B: Standard 'Flip X' Check")
    plt.imshow(overlay)
    plt.axis("off")

    save_path = "forensic_result_fixed.png"
    plt.savefig(save_path, bbox_inches='tight')
    print(f"âœ… ä¿®å¤å®Œæˆï¼Œå›¾ç‰‡å·²ç”Ÿæˆ: {save_path}")

if __name__ == "__main__":
    forensic_investigation_fixed()
'''

with open("debug_investigation_fixed.py", "w") as f:
    f.write(code_content)

print("ğŸš€ æ­£åœ¨è¿è¡Œä¿®å¤ç‰ˆè°ƒæŸ¥è„šæœ¬...")
!conda run -n hybrid_uv_wheel bash -c "export MPLBACKEND=Agg && python debug_investigation_fixed.py"

if os.path.exists("forensic_result_fixed.png"):
    display(Image("forensic_result_fixed.png"))
else:
    print("âŒ è¿è¡Œå¤±è´¥ï¼Œè¯·çœ‹ä¸Šé¢æŠ¥é”™")

"""# Cell 9.3: Overlay æ£€æŸ¥ æ— åè½¬"""

import os

# å®šä¹‰å¯¹æ¯”è„šæœ¬å†…å®¹
diagnostic_script = r'''
import os
import json
import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from pytorch3d.io import load_obj
from pytorch3d.structures import Meshes
from pytorch3d.renderer import (
    PerspectiveCameras, RasterizationSettings, MeshRasterizer,
    MeshRenderer, SoftPhongShader, AmbientLights, TexturesVertex
)

# ================= CONFIG =================
DATA_ROOT = "data/custom/MyNeRFData"
OBJ_NAME = "sponza_gt.obj"
TRANSFORMS = "transforms_train.json"
DEVICE = "cuda"
TARGET_FRAMES = [0, 29] # ç¬¬ 1 å¸§ å’Œ ç¬¬ 30 å¸§
# ==========================================

def run_comparison():
    print(f"ğŸš€ å¯åŠ¨ç»“æ„å¯¹æ¯”è¯Šæ–­: æ£€æŸ¥ Index {TARGET_FRAMES}...")

    # 1. åŠ è½½æ¨¡å‹
    obj_path = os.path.join(DATA_ROOT, OBJ_NAME)
    verts, faces, _ = load_obj(obj_path)
    verts = verts.to(DEVICE).float()
    faces_idx = faces.verts_idx.to(DEVICE).long()

    # æ³•çº¿ç€è‰²ï¼šè§‚å¯Ÿå‡ ä½•è½®å»“
    temp_mesh = Meshes(verts=[verts], faces=[faces_idx])
    normals = temp_mesh.verts_normals_packed()
    verts_rgb = (normals + 1.0) / 2.0
    textures = TexturesVertex(verts_features=verts_rgb[None])
    mesh = Meshes(verts=[verts], faces=[faces_idx], textures=textures)

    # 2. åŠ è½½å…ƒæ•°æ®
    with open(os.path.join(DATA_ROOT, TRANSFORMS), "r") as f:
        meta = json.load(f)

    camera_angle_x = float(meta["camera_angle_x"])
    lights = AmbientLights(device=DEVICE, ambient_color=((1.0, 1.0, 1.0),))

    results = []

    for idx in TARGET_FRAMES:
        frame = meta["frames"][idx]
        img_path = os.path.join(DATA_ROOT, frame["file_path"] + ".png")
        if not os.path.exists(img_path):
            img_path = img_path.replace(".png", ".jpg")

        gt_image = np.array(Image.open(img_path).convert("RGB")) / 255.0
        H, W, _ = gt_image.shape

        c2w = np.array(frame["transform_matrix"], dtype=np.float32)
        c2w_t = torch.from_numpy(c2w).to(DEVICE)

        R_c2w = c2w_t[:3, :3]
        C = c2w_t[:3, 3]
        R_w2c = R_c2w.t()
        T_w2c = -R_w2c @ C

        focal = 0.5 * W / np.tan(0.5 * camera_angle_x)
        cameras = PerspectiveCameras(
            device=DEVICE,
            R=R_w2c.t().unsqueeze(0), # PyTorch3D å†…éƒ¨ä½¿ç”¨è¡Œå‘é‡ä¹˜æ³•ï¼Œæ‰€ä»¥ä¼ è½¬ç½®
            T=T_w2c.unsqueeze(0),
            focal_length=((focal, focal),),
            principal_point=((W/2, H/2),),
            image_size=((H, W),),
            in_ndc=False
        )

        raster_settings = RasterizationSettings(image_size=(H, W), blur_radius=0.0, faces_per_pixel=1, cull_backfaces=False)
        renderer = MeshRenderer(
            rasterizer=MeshRasterizer(cameras=cameras, raster_settings=raster_settings),
            shader=SoftPhongShader(device=DEVICE, cameras=cameras, lights=lights)
        )

        render_rgba = renderer(mesh)[0].cpu().numpy()
        render_rgb = render_rgba[..., :3]
        results.append((gt_image, render_rgb, idx))

    fig, axes = plt.subplots(2, 2, figsize=(20, 16))
    for i, (gt, ren, idx) in enumerate(results):
        axes[i, 0].imshow(gt)
        axes[i, 0].set_title(f"Frame {idx}: Unity Photo", fontsize=16)
        axes[i, 0].axis("off")

        axes[i, 1].imshow(ren)
        axes[i, 1].set_title(f"Frame {idx}: Pytorch3D Render (Raw)", fontsize=16)
        axes[i, 1].axis("off")

    plt.tight_layout()
    output_name = "frame_comparison_result.png"
    plt.savefig(output_name)
    print(f"âœ… å¯¹æ¯”å›¾å·²ç”Ÿæˆ: {output_name}")

if __name__ == "__main__":
    run_comparison()
'''

# å†™å…¥æ–‡ä»¶
with open("compare_script.py", "w") as f:
    f.write(diagnostic_script)

# æ‰§è¡Œè¯Šæ–­
print("ğŸš€ æ­£åœ¨è¿è¡Œå¯¹æ¯”è¯Šæ–­...")
!source activate hybrid_uv_wheel && export MPLBACKEND=Agg && python compare_script.py

# æ˜¾ç¤ºç»“æœ
from IPython.display import Image, display
if os.path.exists("frame_comparison_result.png"):
    display(Image("frame_comparison_result.png"))

#è¯Šæ–­

import os

# å®šä¹‰å¯¹æ¯”è„šæœ¬å†…å®¹
diagnostic_script = r'''
import os
import json
import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from pytorch3d.io import load_obj
from pytorch3d.structures import Meshes
from pytorch3d.renderer import (
    PerspectiveCameras, RasterizationSettings, MeshRasterizer,
    MeshRenderer, SoftPhongShader, AmbientLights, TexturesVertex
)

# ================= CONFIG =================
DATA_ROOT = "data/custom/MyNeRFData"
OBJ_NAME = "sponza_gt.obj"
TRANSFORMS = "transforms_train.json"
DEVICE = "cuda"
TARGET_FRAMES = [0, 29] # ç¬¬ 1 å¸§ å’Œ ç¬¬ 30 å¸§
# ==========================================

def run_comparison():
    print(f"ğŸš€ å¯åŠ¨ç»“æ„å¯¹æ¯”è¯Šæ–­: æ£€æŸ¥ Index {TARGET_FRAMES}...")

    # 1. åŠ è½½æ¨¡å‹
    obj_path = os.path.join(DATA_ROOT, OBJ_NAME)
    verts, faces, _ = load_obj(obj_path)
    verts = verts.to(DEVICE).float()
    faces_idx = faces.verts_idx.to(DEVICE).long()

    # æ³•çº¿ç€è‰²ï¼šè§‚å¯Ÿå‡ ä½•è½®å»“
    temp_mesh = Meshes(verts=[verts], faces=[faces_idx])
    normals = temp_mesh.verts_normals_packed()
    verts_rgb = (normals + 1.0) / 2.0
    textures = TexturesVertex(verts_features=verts_rgb[None])
    mesh = Meshes(verts=[verts], faces=[faces_idx], textures=textures)

    # 2. åŠ è½½å…ƒæ•°æ®
    with open(os.path.join(DATA_ROOT, TRANSFORMS), "r") as f:
        meta = json.load(f)

    camera_angle_x = float(meta["camera_angle_x"])
    lights = AmbientLights(device=DEVICE, ambient_color=((1.0, 1.0, 1.0),))

    conversions = [
        ("world_flip_z", "world", np.diag([1.0, 1.0, -1.0, 1.0]).astype(np.float32)),
        ("world_flip_x", "world", np.diag([-1.0, 1.0, 1.0, 1.0]).astype(np.float32)),
        ("camera_flip_z", "camera", np.diag([1.0, 1.0, -1.0, 1.0]).astype(np.float32)),
        ("camera_flip_x", "camera", np.diag([-1.0, 1.0, 1.0, 1.0]).astype(np.float32)),
    ]

    for name, mode, S in conversions:
        results = []

        for idx in TARGET_FRAMES:
            frame = meta["frames"][idx]
            img_path = os.path.join(DATA_ROOT, frame["file_path"] + ".png")
            if not os.path.exists(img_path):
                img_path = img_path.replace(".png", ".jpg")

            gt_image = np.array(Image.open(img_path).convert("RGB")) / 255.0
            H, W, _ = gt_image.shape

            # --- [çŸ©é˜µè½¬æ¢ï¼šåæ ‡ç³»åˆ‡æ¢] ---
            c2w = np.array(frame["transform_matrix"], dtype=np.float32)
            if mode == "world":
                c2w = S @ c2w
            else:
                c2w = c2w @ S
            c2w_t = torch.from_numpy(c2w).to(DEVICE)

            # 1. è®¡ç®— W2C (R = R_c2w.T, T = -R_w2c * Pos)
            R_c2w = c2w_t[:3, :3]
            C = c2w_t[:3, 3]
            R_w2c = R_c2w.t()
            T_w2c = -R_w2c @ C

            focal = 0.5 * W / np.tan(0.5 * camera_angle_x)
            cameras = PerspectiveCameras(
                device=DEVICE,
                R=R_w2c.t().unsqueeze(0), # PyTorch3D å†…éƒ¨ä½¿ç”¨è¡Œå‘é‡ä¹˜æ³•ï¼Œæ‰€ä»¥ä¼ è½¬ç½®
                T=T_w2c.unsqueeze(0),
                focal_length=((focal, focal),),
                principal_point=((W/2, H/2),),
                image_size=((H, W),),
                in_ndc=False
            )

            # 3. æ¸²æŸ“
            raster_settings = RasterizationSettings(image_size=(H, W), blur_radius=0.0, faces_per_pixel=1, cull_backfaces=False)
            renderer = MeshRenderer(
                rasterizer=MeshRasterizer(cameras=cameras, raster_settings=raster_settings),
                shader=SoftPhongShader(device=DEVICE, cameras=cameras, lights=lights)
            )

            render_rgba = renderer(mesh)[0].cpu().numpy()
            render_rgb = render_rgba[..., :3]
            results.append((gt_image, render_rgb, idx))

        # 4. ç»˜å›¾å±•ç¤º
        fig, axes = plt.subplots(2, 2, figsize=(20, 16))
        for i, (gt, ren, idx) in enumerate(results):
            axes[i, 0].imshow(gt)
            axes[i, 0].set_title(f"Frame {idx}: Unity Photo", fontsize=16)
            axes[i, 0].axis("off")

            axes[i, 1].imshow(ren)
            axes[i, 1].set_title(f"Frame {idx}: Pytorch3D Render ({name})", fontsize=16)
            axes[i, 1].axis("off")

        plt.tight_layout()
        output_name = f"frame_comparison_result_{name}.png"
        plt.savefig(output_name)
        print(f"âœ… å¯¹æ¯”å›¾å·²ç”Ÿæˆ: {output_name}")

if __name__ == "__main__":
    run_comparison()
'''

# å†™å…¥æ–‡ä»¶
with open("compare_script.py", "w") as f:
    f.write(diagnostic_script)

# æ‰§è¡Œè¯Šæ–­
print("ğŸš€ æ­£åœ¨è¿è¡Œåæ ‡ç³»åˆ‡æ¢å¯¹æ¯”è¯Šæ–­...")
!source activate hybrid_uv_wheel && export MPLBACKEND=Agg && python compare_script.py

# æ˜¾ç¤ºç»“æœ
from IPython.display import Image, display
for name in ["world_flip_z", "world_flip_x", "camera_flip_z", "camera_flip_x"]:
    output_name = f"frame_comparison_result_{name}.png"
    if os.path.exists(output_name):
        display(Image(output_name))

"""# Cell 9.1: ä½¿ç”¨ xatlas ä¿®å¤ UV é‡å å¹¶å¯¼å‡º OBJ"""

"""# Cell 9.1: ä½¿ç”¨ xatlas ä¿®å¤ UV é‡å å¹¶å¯¼å‡º OBJ"""
# ç”¨é€”ï¼š
# - è°ƒç”¨ uv_unwrap_xatlas.pyï¼Œå¯¹åŸå§‹ OBJ åš UV é‡æ˜ å°„ï¼Œç”Ÿæˆ sponza_gt_unwarpped.obj
# è¯´æ˜ï¼š
# - ä»…å½“ä½ éœ€è¦é‡æ–°ç”Ÿæˆ unwrapped OBJï¼ˆæˆ–éªŒè¯ xatlas ç»“æœï¼‰æ—¶è¿è¡Œ
# - ç”Ÿæˆçš„æ–° OBJ ä¼šè‡ªåŠ¨å¤‡ä»½åˆ° Drive

print("\nğŸš€ [Hybrid 1/2 Extra] xatlas UV é‡æ˜ å°„ï¼ˆä¿æŒé¡¶ç‚¹é¡ºåº/ä½ç½®ä¸å˜ï¼‰...")
!source activate hybrid_uv_wheel && pip install xatlas trimesh

PROJECT_ROOT_HYBRID = "/content/jax3d/jax3d/projects/mobilenerf"
DRIVE_HYBRID_ROOT = "/content/drive/MyDrive/Hybrid_Pipeline"
HYBRID_DATA_ROOT = "data/custom/MyNeRFData"
HYBRID_OBJ_NAME = "sponza_gt.obj"

if os.path.exists(PROJECT_ROOT_HYBRID):
    os.chdir(PROJECT_ROOT_HYBRID)
    cmd = f"""
    source activate hybrid_uv_wheel && \
    python uv_unwrap_xatlas.py --input {HYBRID_DATA_ROOT}/{HYBRID_OBJ_NAME} --output {HYBRID_DATA_ROOT}/sponza_gt_unwarpped.obj
    """
    get_ipython().system(f"bash -c '{cmd}'")

    new_obj = os.path.join(PROJECT_ROOT_HYBRID, HYBRID_DATA_ROOT, "sponza_gt_unwarpped.obj")
    if os.path.exists(new_obj):
        print("âœ… xatlas UV é‡æ˜ å°„å®Œæˆï¼Œå·²ç”Ÿæˆ sponza_gt_unwarpped.obj")
        os.system(f"cp '{new_obj}' '{DRIVE_HYBRID_ROOT}/'")
        print("âœ… å·²å¤‡ä»½åˆ° Drive")
    else:
        print("âŒ xatlas é‡æ˜ å°„è¾“å‡ºä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
else:
    print(f"âŒ æ‰¾ä¸åˆ°é¡¹ç›®ç›®å½•: {PROJECT_ROOT_HYBRID}")

import os

# å®šä¹‰å¯¹æ¯”è„šæœ¬å†…å®¹
diagnostic_script = r'''
import os
import json
import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from pytorch3d.io import load_obj
from pytorch3d.structures import Meshes
from pytorch3d.renderer import (
    PerspectiveCameras, RasterizationSettings, MeshRasterizer,
    MeshRenderer, SoftPhongShader, AmbientLights, TexturesVertex
)

# ================= CONFIG =================
DATA_ROOT = "data/custom/MyNeRFData"
OBJ_NAME = "sponza_gt_unwarpped.obj"
TRANSFORMS = "transforms_train.json"
DEVICE = "cuda"
TARGET_FRAMES = [0, 29] # ç¬¬ 1 å¸§ å’Œ ç¬¬ 30 å¸§
# ==========================================

def run_comparison():
    print(f"ğŸš€ å¯åŠ¨ç»“æ„å¯¹æ¯”è¯Šæ–­: æ£€æŸ¥ Index {TARGET_FRAMES}...")

    # 1. åŠ è½½æ¨¡å‹
    obj_path = os.path.join(DATA_ROOT, OBJ_NAME)
    verts, faces, _ = load_obj(obj_path)
    verts = verts.to(DEVICE).float()
    faces_idx = faces.verts_idx.to(DEVICE).long()

    # æ³•çº¿ç€è‰²ï¼šè§‚å¯Ÿå‡ ä½•è½®å»“
    temp_mesh = Meshes(verts=[verts], faces=[faces_idx])
    normals = temp_mesh.verts_normals_packed()
    verts_rgb = (normals + 1.0) / 2.0
    textures = TexturesVertex(verts_features=verts_rgb[None])
    mesh = Meshes(verts=[verts], faces=[faces_idx], textures=textures)

    # 2. åŠ è½½å…ƒæ•°æ®
    with open(os.path.join(DATA_ROOT, TRANSFORMS), "r") as f:
        meta = json.load(f)

    camera_angle_x = float(meta["camera_angle_x"])
    lights = AmbientLights(device=DEVICE, ambient_color=((1.0, 1.0, 1.0),))

    results = []

    for idx in TARGET_FRAMES:
        frame = meta["frames"][idx]
        img_path = os.path.join(DATA_ROOT, frame["file_path"] + ".png")
        if not os.path.exists(img_path):
            img_path = img_path.replace(".png", ".jpg")

        gt_image = np.array(Image.open(img_path).convert("RGB")) / 255.0
        H, W, _ = gt_image.shape

        c2w = np.array(frame["transform_matrix"], dtype=np.float32)
        c2w_t = torch.from_numpy(c2w).to(DEVICE)

        R_c2w = c2w_t[:3, :3]
        C = c2w_t[:3, 3]
        R_w2c = R_c2w.t()
        T_w2c = -R_w2c @ C

        focal = 0.5 * W / np.tan(0.5 * camera_angle_x)
        cameras = PerspectiveCameras(
            device=DEVICE,
            R=R_w2c.t().unsqueeze(0), # PyTorch3D å†…éƒ¨ä½¿ç”¨è¡Œå‘é‡ä¹˜æ³•ï¼Œæ‰€ä»¥ä¼ è½¬ç½®
            T=T_w2c.unsqueeze(0),
            focal_length=((focal, focal),),
            principal_point=((W/2, H/2),),
            image_size=((H, W),),
            in_ndc=False
        )

        raster_settings = RasterizationSettings(image_size=(H, W), blur_radius=0.0, faces_per_pixel=1, cull_backfaces=False)
        renderer = MeshRenderer(
            rasterizer=MeshRasterizer(cameras=cameras, raster_settings=raster_settings),
            shader=SoftPhongShader(device=DEVICE, cameras=cameras, lights=lights)
        )

        render_rgba = renderer(mesh)[0].cpu().numpy()
        render_rgb = render_rgba[..., :3]
        results.append((gt_image, render_rgb, idx))

    fig, axes = plt.subplots(2, 2, figsize=(20, 16))
    for i, (gt, ren, idx) in enumerate(results):
        axes[i, 0].imshow(gt)
        axes[i, 0].set_title(f"Frame {idx}: Unity Photo", fontsize=16)
        axes[i, 0].axis("off")

        axes[i, 1].imshow(ren)
        axes[i, 1].set_title(f"Frame {idx}: Pytorch3D Render (Raw)", fontsize=16)
        axes[i, 1].axis("off")

    plt.tight_layout()
    output_name = "frame_comparison_result.png"
    plt.savefig(output_name)
    print(f"âœ… å¯¹æ¯”å›¾å·²ç”Ÿæˆ: {output_name}")

if __name__ == "__main__":
    run_comparison()
'''

# å†™å…¥æ–‡ä»¶
with open("compare_script.py", "w") as f:
    f.write(diagnostic_script)

# æ‰§è¡Œè¯Šæ–­
print("ğŸš€ æ­£åœ¨è¿è¡Œå¯¹æ¯”è¯Šæ–­...")
!source activate hybrid_uv_wheel && export MPLBACKEND=Agg && python compare_script.py

# æ˜¾ç¤ºç»“æœ
from IPython.display import Image, display
if os.path.exists("frame_comparison_result.png"):
    display(Image("frame_comparison_result.png"))

"""# Cell 9.2: æ¸²æŸ“å¯¹æ¯”æµ‹è¯• - render_comparison_test.py'''"""

"""# Cell 9.2: æ¸²æŸ“å¯¹æ¯”æµ‹è¯• - render_comparison_test.py"""
# ç”¨é€”ï¼š
# - åœ¨ hybrid_uv_wheel ç¯å¢ƒä¸­è¿è¡Œ render_comparison_test.pyï¼Œå¯¹æ¯”åŸå§‹ vs unwrapped mesh çš„æ¸²æŸ“ä¸è¯¯å·®
# è¯´æ˜ï¼š
# - å®Œå…¨å¯é€‰ï¼Œç”¨äºç¡®è®¤ UV é‡æ˜ å°„æ²¡æœ‰ç ´åå‡ ä½• / æŠ•å½±

import os
from IPython import get_ipython

PROJECT_ROOT_HYBRID = "/content/jax3d/jax3d/projects/mobilenerf"

print("\nğŸš€ [Hybrid 1/2 Extra] è¿è¡Œ render_comparison_test.py åšå‡ ä½•ä¸€è‡´æ€§å¯¹æ¯”...")

if os.path.exists(PROJECT_ROOT_HYBRID):
    os.chdir(PROJECT_ROOT_HYBRID)
    cmd = """
    source activate hybrid_uv_wheel && \
    python render_comparison_test.py
    """
    get_ipython().system(f"bash -c '{cmd}'")
else:
    print(f"âŒ æ‰¾ä¸åˆ°é¡¹ç›®ç›®å½•: {PROJECT_ROOT_HYBRID}")



"""# Cell 11: Hybrid Pipeline Step 2 - è®­ç»ƒ Hybrid Texture + MLP"""
# ä½œç”¨ï¼š
# - åœ¨ Colab é»˜è®¤ Python ç¯å¢ƒä¸­è¿è¡Œ 02_train_hybrid.pyï¼Œè®­ç»ƒ Hybrid çº¹ç† + å° MLPï¼ˆæ‰‹æœºç«¯è¿è¡Œæ—¶æ¨¡å‹ï¼‰
# å‰ç½®ä¾èµ–ï¼š
# - Cell 8-UVï¼šè‡³å°‘åœ¨æœ¬ Runtime ä¸­æˆåŠŸåˆ›å»ºè¿‡ hybrid_uv_wheelï¼ˆä¾› 01 / è¯Šæ–­ä½¿ç”¨ï¼‰
# - Cell 8 Hybrid Workflowï¼šæœ¬ Runtime ä¸­å·²å®‰è£… torch + pytorch3dï¼ˆæœ¬ Cell åªç”¨åˆ°è¿™ä¸€ç¯å¢ƒï¼‰
# - uv_lookup.npz å·²å­˜åœ¨ï¼š
#   * åˆšé€šè¿‡ Cell 9 ç”Ÿæˆï¼Œæˆ–
#   * Drive ä¸­å·²æœ‰ä¸€ä»½ï¼Œæœ¬ Cell ä¼šè‡ªåŠ¨ä» Drive æ¢å¤åˆ°æœ¬åœ°
# è¿è¡Œå»ºè®®ï¼š
# - æ¯æ¬¡éœ€è¦è®­ç»ƒ / ç»§ç»­è®­ç»ƒ Hybrid æ¨¡å‹æ—¶è¿è¡Œ
# - Cell 8 ä¸éœ€è¦æ¯æ¬¡éƒ½é‡è·‘ï¼Œåªåœ¨ Colab é‡å¯åé‡æ–°è¿è¡Œä¸€éå³å¯

import os
import time
import threading
from IPython import get_ipython
from google.colab import drive

PROJECT_ROOT_HYBRID = "/content/jax3d/jax3d/projects/mobilenerf"
DRIVE_HYBRID_ROOT = "/content/drive/MyDrive/Hybrid_Pipeline"


HYBRID_DATA_ROOT_TRAIN = "data/custom/MyNeRFData"
HYBRID_UV_PATH_TRAIN = os.path.join(HYBRID_DATA_ROOT_TRAIN, "uv_lookup.npz")

HYBRID_TEXTURE_SIZE = 2048
HYBRID_BATCH_SIZE = 1024
HYBRID_NUM_ITERS = 300000
HYBRID_LR = 3e-4
HYBRID_DOWNSCALE_TRAIN = 1

HYBRID_CHECKPOINT_PATH = "weights/hybrid_texture_mlp.pth"
HYBRID_ENV_PYTHON = "python"

print("\nğŸš€ [Hybrid 2/2] å¯åŠ¨ Hybrid Texture + MLP è®­ç»ƒ...")

if not os.path.exists("/content/drive"):
    drive.mount("/content/drive")

if not os.path.exists(DRIVE_HYBRID_ROOT):
    os.makedirs(DRIVE_HYBRID_ROOT)

local_weights = os.path.join(PROJECT_ROOT_HYBRID, "weights")
local_samples = os.path.join(PROJECT_ROOT_HYBRID, "samples")
dst_weights = os.path.join(DRIVE_HYBRID_ROOT, "weights")
dst_samples = os.path.join(DRIVE_HYBRID_ROOT, "samples")

def hybrid_background_backup():
    while True:
        try:
            if os.path.exists(local_weights):
                if not os.path.exists(dst_weights):
                    os.makedirs(dst_weights)
                os.system(f"cp -ru '{local_weights}/.' '{dst_weights}/'")
            if os.path.exists(local_samples):
                if not os.path.exists(dst_samples):
                    os.makedirs(dst_samples)
                os.system(f"cp -ru '{local_samples}/.' '{dst_samples}/'")
        except:
            pass
        time.sleep(60)

t = threading.Thread(target=hybrid_background_backup)
t.daemon = True
t.start()

local_uv_path = os.path.join(PROJECT_ROOT_HYBRID, HYBRID_UV_PATH_TRAIN)
drive_uv_path = os.path.join(DRIVE_HYBRID_ROOT, os.path.basename(HYBRID_UV_PATH_TRAIN))

if not os.path.exists(local_uv_path) and os.path.exists(drive_uv_path):
    os.makedirs(os.path.dirname(local_uv_path), exist_ok=True)
    os.system(f"cp '{drive_uv_path}' '{local_uv_path}'")
    print(f"ğŸ”„ å·²ä» Drive æ¢å¤ uv_lookup.npz åˆ°æœ¬åœ°: {local_uv_path}")

if os.path.exists(PROJECT_ROOT_HYBRID):
    os.chdir(PROJECT_ROOT_HYBRID)
    cmd = f"""
export MPLBACKEND=Agg && {HYBRID_ENV_PYTHON} 02_train_hybrid.py \
  --data_root='{HYBRID_DATA_ROOT_TRAIN}' \
  --uv_path='{HYBRID_UV_PATH_TRAIN}' \
  --texture_size={HYBRID_TEXTURE_SIZE} \
  --batch_size={HYBRID_BATCH_SIZE} \
  --num_iters={HYBRID_NUM_ITERS} \
  --lr={HYBRID_LR} \
  --device='auto' \
  --downscale={HYBRID_DOWNSCALE_TRAIN} \
  --checkpoint='{HYBRID_CHECKPOINT_PATH}'
"""
    get_ipython().system(cmd)

    print("\nğŸ“¦ æ­£åœ¨å¤‡ä»½ Hybrid è®­ç»ƒç»“æœåˆ° Drive...")
    if not os.path.exists(DRIVE_HYBRID_ROOT):
        os.makedirs(DRIVE_HYBRID_ROOT)

    local_weights = os.path.join(PROJECT_ROOT_HYBRID, "weights")
    local_samples = os.path.join(PROJECT_ROOT_HYBRID, "samples")

    if os.path.exists(local_weights):
        dst_weights = os.path.join(DRIVE_HYBRID_ROOT, "weights")
        if not os.path.exists(dst_weights):
            os.makedirs(dst_weights)
        os.system(f"cp -ru '{local_weights}/.' '{dst_weights}/'")

    if os.path.exists(local_samples):
        dst_samples = os.path.join(DRIVE_HYBRID_ROOT, "samples")
        if not os.path.exists(dst_samples):
            os.makedirs(dst_samples)
        os.system(f"cp -ru '{local_samples}/.' '{dst_samples}/'")

    print(f"\nâœ… Hybrid è®­ç»ƒç»“æœå·²ä¿å­˜è‡³: {DRIVE_HYBRID_ROOT}")
else:
    print(f"âŒ æ‰¾ä¸åˆ°é¡¹ç›®ç›®å½•: {PROJECT_ROOT_HYBRID}")

import json
import numpy as np

# è¯»å–ä½ çš„ JSON
with open("data/custom/MyNeRFData/transforms_train.json", "r") as f:
    data = json.load(f)

# è·å–ç¬¬ä¸€å¸§çš„çŸ©é˜µ
matrix_data = np.array(data["frames"][0]["transform_matrix"])
print("ğŸ” ç¬¬ä¸€å¸§åŸå§‹çŸ©é˜µ (JSON):\n", matrix_data)

# ã€è¯Šæ–­ 1ã€‘æ£€æŸ¥æ—‹è½¬çŸ©é˜µæ˜¯å¦æ­£äº¤ (æ˜¯å¦å‘ç”Ÿäº†æ‰­æ›²/å‰ªåˆ‡)
# æå–å‰3x3 (æ—‹è½¬éƒ¨åˆ†)
R = matrix_data[:3, :3]
# è®¡ç®— R * R_transpose (å¦‚æœæ˜¯å®Œç¾çš„æ—‹è½¬çŸ©é˜µï¼Œç»“æœåº”è¯¥æ˜¯å•ä½çŸ©é˜µ Identity)
ortho_check = np.dot(R, R.T)

print("\nğŸ“Š æ­£äº¤æ€§æ£€æŸ¥ (å¯¹è§’çº¿åº”ä¸º1ï¼Œå…¶ä»–åº”æ¥è¿‘0):")
print(ortho_check)

# ã€è¯Šæ–­ 2ã€‘æ£€æŸ¥è¡Œåˆ—å¼ (Determinant)
# å¦‚æœæ˜¯æ—‹è½¬çŸ©é˜µï¼Œdet åº”è¯¥æ˜¯ 1ã€‚å¦‚æœæ˜¯é•œåƒçŸ©é˜µï¼Œdet æ˜¯ -1ã€‚
det = np.linalg.det(R)
print(f"\nğŸ“ è¡Œåˆ—å¼ (Determinant): {det:.4f}")
if np.isclose(det, 1.0, atol=1e-3):
    print("   -> âœ… çº¯æ—‹è½¬çŸ©é˜µ (å³æ‰‹/å·¦æ‰‹ç³»ä¿æŒä¸€è‡´)")
elif np.isclose(det, -1.0, atol=1e-3):
    print("   -> ğŸª åŒ…å«é•œåƒ (Flip) çš„çŸ©é˜µ")
else:
    print("   -> âŒ çŸ©é˜µå·²å˜å½¢/ç¼©æ”¾ (è¿™å°±æ˜¯å€¾æ–œçš„æ ¹æºï¼)")

# ã€è¯Šæ–­ 3ã€‘æ£€æŸ¥ä½ç½®
pos = matrix_data[:3, 3]
print(f"\nğŸ“ ç›¸æœºä½ç½®: {pos}")
